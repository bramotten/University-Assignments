{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VmQBiivavVAu"
   },
   "source": [
    "# HMM Experiments\n",
    "\n",
    "Lennart Beekhuis, TODO\n",
    "\n",
    "Bram Otten, 10992456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3730,
     "output_extras": [
      {
       "item_id": 44
      },
      {
       "item_id": 82
      },
      {
       "item_id": 98
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120987,
     "status": "ok",
     "timestamp": 1520682623917,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110618989541510237728"
     },
     "user_tz": -60
    },
    "id": "PqWxHmX4vVAx",
    "outputId": "84835a88-5989-4aeb-ef1f-cce5087f9402"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "try:\n",
    "    treebank_sents = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "except:\n",
    "    nltk.download()\n",
    "    treebank_sents = nltk.corpus.treebank.tagged_sents(tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iu72EQZevVA1"
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "4Jz2ZULZvVA2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def extract_sentences(treebank_corpus):\n",
    "    sentences = []\n",
    "    for observations in treebank_corpus:\n",
    "        sentences.append([x for x, c in observations])\n",
    "    return sentences\n",
    "\n",
    "\n",
    "def extract_tags(treebank_corpus):\n",
    "    tags = []\n",
    "    for observations in treebank_corpus:\n",
    "        tags.append([c for x, c in observations])\n",
    "    return tags\n",
    "\n",
    "\n",
    "class HMMLM:\n",
    "    \"\"\"\n",
    "    This is our HMM language model class.\n",
    "\n",
    "    It will be responsible for estimating parameters by MLE\n",
    "    as well as computing probabilities using the HMM.\n",
    "\n",
    "    We will use Laplace smoothing by default (because we do not want \n",
    "    to assign 0 probabilities).\n",
    "\n",
    "    GUIDELINES:\n",
    "        - by convention we will use the string '-UNK-' for an unknown POS tag\n",
    "            - and '<unk>' for an unknown word\n",
    "        - don't forget that with Laplace smoothing the unknown symbols have \n",
    "          to be in the support\n",
    "          of distributions\n",
    "        - now you will have 2 types of distributions, so you should deal \n",
    "          with unknown symbols\n",
    "          for both of them\n",
    "        - we also need padding for sentences and tag sequences, by convention \n",
    "          we will use\n",
    "            - '-BOS-' and '-EOS-' for padding tag sequences\n",
    "            - '<s>' and '</s>' for padding sentences\n",
    "        - do recall that '-BOS-' is **not** a valid tag\n",
    "            in other words we never *generate* '-BOS-' tags, we only pretend \n",
    "            they occur at\n",
    "            the 0th position of the tag sequence in order to provide \n",
    "            conditioning context for the first actual tag\n",
    "        - similarly, '<s>' is not a valid word\n",
    "            in other words, we never *generate* '<s>' as a word\n",
    "            in fact '<s>' is optional as no emission event is based on it\n",
    "        - on the other hand, '-EOS-' is a valid tag\n",
    "            you should model it as the last event of a tag sequence\n",
    "        - similarly, '</s>' is a valid word\n",
    "            you should consider it as the last event of a sentence\n",
    "\n",
    "    You can use whatever data structures you like for cpds\n",
    "        - we suggest python dict or collections.defaultdict\n",
    "            but you are free to experiment with list and/or np.array if you \n",
    "            like\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, transition_alpha=1.0, emission_alpha=1.0):\n",
    "        self._vocab = set()\n",
    "        self._tagset = set()\n",
    "        self._emission_cpds = dict()\n",
    "        self._transition_cpds = dict()\n",
    "        self._transition_alpha = transition_alpha\n",
    "        self._emission_alpha = emission_alpha\n",
    "\n",
    "    def tagset(self):\n",
    "        \"\"\"\n",
    "        Return the tagset: a set of all tags seen by the model (including \n",
    "        '-UNK-').\n",
    "\n",
    "        You can modify this if you judge necessary (for example, because \n",
    "        you decided  to use different datastructures, but do note that we \n",
    "        provide you an implementation of the Viterbi algorithm that\n",
    "        expects this functionality).\n",
    "        \"\"\"\n",
    "        # the -BOS- tag is just something for internal representation\n",
    "        #  in case you have added it to the tagset, we are removing it here\n",
    "        #  as keeping it would be bad for algorithms such as Viterbi\n",
    "        # the -UNK- tag must be in the support (due to Laplace smoothing)\n",
    "        #  thus in case you forgot it, we are adding it now\n",
    "        return self._tagset - {'-BOS-'} | {'-UNK-'}\n",
    "\n",
    "    def vocab(self):\n",
    "        \"\"\"\n",
    "        Return the vocabulary of words: all words seen by the model \n",
    "        (including '<unk>').\n",
    "\n",
    "        You can modify this if you judge necessary (for example, because \n",
    "        you decided to use different datastructures, but do note that \n",
    "        we provide you an implementation of the Viterbi algorithm that \n",
    "        expects this functionality).\n",
    "        \"\"\"\n",
    "        # the <s> token is just something for internal representation\n",
    "        #  in case you have added it to the vocabulary, we are removing it here\n",
    "        # the <unk> word must be in the support (due to Laplace smoothing)\n",
    "        #  thus in case you forgot it, we are adding it now\n",
    "        return self._vocab - {'<s>'} | {'<unk>'}\n",
    "\n",
    "    def preprocess_sentence(self, sentence, bos=True, eos=True):\n",
    "        \"\"\"\n",
    "        Preprocess a sentence by lowercasing its words and possibly padding it.\n",
    "\n",
    "        :param sentence: a list of tokens (each a string)\n",
    "        :param bos: if True you will get <s> at the beginning\n",
    "        :param eos: if True you will get </s> at the end\n",
    "        :returns: a list of tokens (lowercased strings)\n",
    "        \"\"\"\n",
    "        # lowercase\n",
    "        sentence = [x.lower() for x in sentence]\n",
    "        # optional padding\n",
    "        if bos:\n",
    "            sentence = ['<s>'] + sentence\n",
    "        if eos:\n",
    "            sentence = sentence + ['</s>']\n",
    "        return sentence\n",
    "\n",
    "    def preprocess_tag_sequence(self, tag_sequence, bos=True, eos=True):\n",
    "        \"\"\"\n",
    "        Preprocess a tag sequence with optional padding.\n",
    "\n",
    "        :param tag_sequence: a list of tags (each a string)\n",
    "        :param bos: if True you will get -BOS- at the beginning\n",
    "        :param eos: if True you will get -EOS- at the end\n",
    "        :returns: a list of tokens\n",
    "        \"\"\"\n",
    "        # optional padding\n",
    "        if bos:\n",
    "            tag_sequence = ['-BOS-'] + tag_sequence\n",
    "        if eos:\n",
    "            tag_sequence = tag_sequence + ['-EOS-']\n",
    "        return tag_sequence\n",
    "\n",
    "    def estimate_model(self, treebank):\n",
    "        \"\"\"\n",
    "        :param treebank: a sequence of observations as provided by nltk\n",
    "            each observation is a list of pairs (x_i, c_i)\n",
    "            and they have not yet been pre-processed\n",
    "\n",
    "        Estimate the model parameters.\n",
    "\n",
    "        This method does not have to return anything, it simply computes \n",
    "        the necessary cpds.\n",
    "        \"\"\"\n",
    "        reference_tagged_words = nltk.corpus.treebank.tagged_words(\n",
    "            tagset='universal')\n",
    "        self._vocab = set([w for (w, _) in reference_tagged_words])\n",
    "        self._tagset = set([t for (_, t) in reference_tagged_words])\n",
    "\n",
    "        self._tagset.add('-EOS-')\n",
    "        self._tagset.add('-UNK-')\n",
    "        # Init emissions inbetween so it doesn't unnecessarily contain the BOS\n",
    "        # tag\n",
    "        self._emission_cpds = {\n",
    "            tag: {\n",
    "                '<unk>': self._emission_alpha\n",
    "            }\n",
    "            for tag in self._tagset\n",
    "        }\n",
    "        self._tagset.add('-BOS-')\n",
    "        for key in self._tagset:\n",
    "            self._transition_cpds[key] = dict.fromkeys(self.tagset(),\n",
    "                                                       self._transition_alpha)\n",
    "\n",
    "        sentences = extract_sentences(treebank)\n",
    "        tree_tags = extract_tags(treebank)\n",
    "        for sentence_i, tags in enumerate(tree_tags):\n",
    "            tags = self.preprocess_tag_sequence(tags)\n",
    "            for i in range(1, len(tags)):\n",
    "                tag1 = tags[i - 1]\n",
    "                tag2 = tags[i]\n",
    "                self._transition_cpds[tag1][tag2] += 1\n",
    "\n",
    "            sentt = self.preprocess_sentence(sentences[sentence_i])\n",
    "            for word_i, tag in enumerate(tags):\n",
    "                word = sentt[word_i]\n",
    "                if word == '<s>' or word == '</s>' or tag == '-BOS-':\n",
    "                    continue\n",
    "                if word not in self._emission_cpds[tag]:\n",
    "                    self._vocab.add(word)\n",
    "                    self._emission_cpds[tag][word] = self._emission_alpha\n",
    "                self._emission_cpds[tag][word] += 1\n",
    "                # So the value will be 1 + emission_alpha for everything\n",
    "                # that occurs with this tag and later be made emission_alpha\n",
    "                # for every word that occurs at all.\n",
    "\n",
    "        # By now the vocab is full, throw into every tag's emission cpd.\n",
    "        # This doesn't really make sense (we have unk for this)\n",
    "        # but gets us closer to the wanted P value.\n",
    "        for tag in self._tagset:\n",
    "            if tag == '-BOS-':\n",
    "                continue\n",
    "            for word in self._vocab:\n",
    "                if word not in self._emission_cpds[tag]:\n",
    "                    self._emission_cpds[tag][word] = self._emission_alpha\n",
    "\n",
    "    def transition_parameter(self, previous_tag, current_tag):\n",
    "        \"\"\"\n",
    "        This method returns the transition probability for tag given \n",
    "        the previous tag.\n",
    "\n",
    "        Tips: do not forget that we have a smoothed model, thus\n",
    "            - if the either tag was never seen, you should pretend it \n",
    "              to be '-UNK-'\n",
    "\n",
    "        :param previous_tag: the previous tag (str)\n",
    "        :param current_tag: the current tag (str)\n",
    "        :return: transition parameter\n",
    "        \"\"\"\n",
    "        if current_tag not in self.tagset():\n",
    "            current_tag = '-UNK-'\n",
    "        if previous_tag not in self.tagset():\n",
    "            previous_tag = '-UNK-'\n",
    "\n",
    "        count_pair = self._transition_cpds[previous_tag][current_tag]\n",
    "        count_single = 0\n",
    "        for value in self._transition_cpds[previous_tag].values():\n",
    "            count_single += value\n",
    "\n",
    "        return count_pair / count_single\n",
    "\n",
    "    def emission_parameter(self, tag, word):\n",
    "        \"\"\"\n",
    "        This method returns the emission probability for a word given a tag.\n",
    "        Tips: do not forget that we have a smoothed model, thus\n",
    "            - if the tag was never seen, you should pretend it to be '-UNK-'\n",
    "            - similarly, if the word was never seen, you shoud pretend \n",
    "              it to be '<unk>'\n",
    "\n",
    "        :param tag: the current tag (str)\n",
    "        :param word: the current word (str)\n",
    "        :return: the emission probability\n",
    "        \"\"\"\n",
    "        word = word.lower()\n",
    "        if tag not in self.tagset():\n",
    "            tag = '-UNK-'\n",
    "        if word not in self._emission_cpds[tag]:\n",
    "            word = '<unk>'\n",
    "\n",
    "        count_tag_word = self._emission_cpds[tag][word]\n",
    "        count_tag = 0\n",
    "        for value in self._emission_cpds[tag].values():\n",
    "            count_tag += value\n",
    "\n",
    "        return count_tag_word / count_tag\n",
    "\n",
    "    def joint_parameter(self, previous_tag, current_tag, word):\n",
    "        \"\"\"\n",
    "        This method returns the joint probability of (current tag, word) \n",
    "        given the previous tag according to Equation (3)\n",
    "\n",
    "        :param previous_tag: the previous tag (str)\n",
    "        :param current_tag: the current tag (str)\n",
    "        :param word: the current word (str)\n",
    "        :returns: P(word, current_tag|previous_tag)\n",
    "        \"\"\"\n",
    "        return self.transition_parameter(previous_tag, current_tag) * \\\n",
    "            self.emission_parameter(current_tag, word)\n",
    "\n",
    "    def marginal_x_given_cprev(self, previous_tag, word):\n",
    "        \"\"\"\n",
    "        Return P(x|prev) as defined in Equation (4) by marginalising current \n",
    "        tag.\n",
    "\n",
    "        :param previous_tag: the previous tag (str)\n",
    "        :param word: the current word (str)\n",
    "        \"\"\"\n",
    "        total = 0\n",
    "        word = word.lower()\n",
    "        for cu_tag in self.tagset():\n",
    "            p = self.joint_parameter(previous_tag, cu_tag, word)\n",
    "            total += p\n",
    "        return total\n",
    "\n",
    "    def log_joint(self, sentence, tag_sequence):\n",
    "        \"\"\"\n",
    "        Implement the logarithm of the joint probability over a sentence and \n",
    "        tag sequence as in Equation (8)\n",
    "\n",
    "        :param sentence: a sequence of words (each a string) not yet preprocessed\n",
    "        :param tag_sequence: a sequence of tags (each a string) not yet preprocessed\n",
    "        :returns: log P(x_1^n, c_1^n|n) as defined in Equation (8)\n",
    "        \"\"\"\n",
    "        sentence = self.preprocess_sentence(sentence)\n",
    "        tag_sequence = self.preprocess_tag_sequence(tag_sequence)\n",
    "\n",
    "        counter = 0\n",
    "        for i in range(1, len(sentence)):\n",
    "            counter += np.log(\n",
    "                self.joint_parameter(tag_sequence[i - 1], tag_sequence[i],\n",
    "                                     sentence[i]))\n",
    "\n",
    "        return counter\n",
    "\n",
    "    def log_marginal(self, sentence):\n",
    "        \"\"\"\n",
    "        Implement the logarithm of the marginal probability of a sentence as in Equation (9)\n",
    "            by marginalisation of all possible tag sequences.\n",
    "\n",
    "        :param sentence: a sequence of words (each a string) not yet preprocessed\n",
    "        :returns: log P(x_1^m|n) as defined in Equation (9)\n",
    "        \"\"\"\n",
    "        sentence = self.preprocess_sentence(sentence)\n",
    "        total = 0\n",
    "        for word in sentence[1:]:\n",
    "            p = 0\n",
    "            for previous_tag in self.tagset():\n",
    "                p += self.marginal_x_given_cprev(previous_tag, word)\n",
    "            total += np.log(p)\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     39
    ],
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vTJIx1N7vVA5"
   },
   "outputs": [],
   "source": [
    "def log_perplexity(sentences, hmm):\n",
    "    \"\"\"\n",
    "    TYPE YOUR SOLUTION\n",
    "\n",
    "    For a dataset of sentences (each sentence is a list of words)\n",
    "        and an instance of the HMMLM class\n",
    "        return the log perplexity as defined in Equation (12)\n",
    "    \"\"\"\n",
    "    total_log_p = 0\n",
    "    n = 0\n",
    "    for sentence in sentences:\n",
    "        # Only care about words, so use this marginal. Each sentence has\n",
    "        n += len(sentence)\n",
    "        total_log_p += hmm.log_marginal(sentence) * (-1 / n)\n",
    "    return total_log_p  # * (-1 / n)\n",
    "\n",
    "\n",
    "def accuracy(gold_sequences, pred_sequences):\n",
    "    \"\"\"\n",
    "    Return percentage of instances in the test data that our tagger labeled correctly.\n",
    "\n",
    "    :param gold_sequences: a list of tag sequences that can be assumed to be correct\n",
    "    :param pred_sequences: a list of tag sequences predicted by Viterbi\n",
    "    \"\"\"\n",
    "\n",
    "    pred_counter = 0\n",
    "    token_counter = 0\n",
    "\n",
    "    for i, gold in enumerate(gold_sequences):\n",
    "        gold = gold_sequences[i]\n",
    "        pred = pred_sequences[i]\n",
    "        for j in range(len(gold)):\n",
    "            if gold[j] == pred[j]:\n",
    "                pred_counter += 1\n",
    "        token_counter += len(pred)\n",
    "\n",
    "    return pred_counter / token_counter\n",
    "\n",
    "\n",
    "def viterbi_recursion(sentence, hmm):\n",
    "    \"\"\"\n",
    "    Computes the best possible tag sequence for a given input\n",
    "    and also returns it log probability.\n",
    "\n",
    "    This implementation uses recursion.\n",
    "\n",
    "    :returns: tag sequence, log probability\n",
    "    \"\"\"\n",
    "    # here we pad the sentence with </s> only\n",
    "    sentence = hmm.preprocess_sentence(sentence, bos=False, eos=True)\n",
    "    # this is the length (but recall that padding added 1 token)\n",
    "    n = len(sentence)\n",
    "    # this is the complete tagset, which for convenience we will turn into a\n",
    "    # list\n",
    "    tagset = list(hmm.tagset())\n",
    "    t = len(tagset)\n",
    "    # We need a table to store log alpha(i, j) values\n",
    "    # - where i is an integer from 0 to n-1 which refers to a position in the list `sentence`\n",
    "    #   i.e. sentence[i]\n",
    "    # - and j is an integer from 0 to t-1 that refers to a tag in the list `tagset`\n",
    "    #   i.e. tagset[j]\n",
    "    # - together (i, j) means that we are setting `C_i = tagset[j]`\n",
    "    # - we will be exploring the space of possible tags per position\n",
    "    #   thus our table has as many as n * t cells\n",
    "    # - Recall that the value \\log \\alpha(i, j)\n",
    "    #   corresponds to the log probability value of the best\n",
    "    #   path (C_1, ..., C_i) such that C_i = j\n",
    "    #   in other words the log probability of the best sequence up to the ith token where C_i = j\n",
    "    # At the beginning path probabilities have not been computed, we use a probability of 0 to indicate that\n",
    "    #  as we will be computing log probabilities, we use -inf instead\n",
    "    #  numpy arrays are very handy and we can actually use the quantity -inf\n",
    "    log_alpha_table = np.full([n, t], -float('inf'))\n",
    "    # In a best path algorithm we are interested in two things\n",
    "    #  the best score (or best log probability)\n",
    "    #  as well as the path that corresponds to the best score\n",
    "    # We compute the best score by moving i forward from 0 to n-1 computing the maximum value\n",
    "    #  and we traverse the table backwards following the path that led to the maximum\n",
    "    #  thus we create a table of \"back pointers\"\n",
    "    #  this is an integer for each cell (i, j) that tells us which tag `p` for position `i - 1`\n",
    "    #   leads to the score stored in `log_alpha_table[i, j]`\n",
    "    back_pointer_table = np.full([n, t], -1, dtype=int)\n",
    "\n",
    "    # Here we define the log alpha recursion\n",
    "    def log_alpha(i, j):\n",
    "        \"\"\"\n",
    "        This function returns\n",
    "                max_{c_1, ..., c_i=j} log P(c_1, ..., c_i=j)\n",
    "            where i is a (0-based) position in `sentence`\n",
    "            and j is a (0-based) position in `tagset`\n",
    "        \"\"\"\n",
    "        if i == 0:  # we do not need to tag the 0th position and it should not affect the probability\n",
    "            return 0.  # np.log(1)\n",
    "        # When we implement dynamic programs, we like to re-use computations already made\n",
    "        # thus first of all we test if we have already computed a value for this cell\n",
    "        # if so, it will not have a zero probability (-inf in log space)\n",
    "        if log_alpha_table[i, j] != -float('inf'):\n",
    "            # then we can simply return it\n",
    "            return log_alpha_table[i, j]\n",
    "        # At this point we know we have not yet computed a score for this path\n",
    "        #  thus we proceed to compute it\n",
    "        # We will have to figure out the log prob of the best prefix\n",
    "        #  and which tag best continues from it\n",
    "        # There are exactly t classes that may tag this position\n",
    "        #  thus we just go over the tagset trying one at a time\n",
    "        #  and memorise the score we would have if we would select them\n",
    "        path_max_log_prob = np.full(t, -float('inf'))\n",
    "        for p in range(t):\n",
    "            # this is the essential part of the recursion\n",
    "            # we ask for the best score associated with the previous position\n",
    "            #  had it been tagged with p\n",
    "            #  and we incorporate the probability of C_i = tagset[j] given that C_{i-1} = tagset[p]\n",
    "            # as well as the probability of X_i = sentence[i] given that C_i =\n",
    "            # tagset[j]\n",
    "            path_max_log_prob[p] = log_alpha(\n",
    "                i - 1, p) + np.log(hmm.joint_parameter(tagset[p], tagset[j], sentence[i]))\n",
    "        # From all possibilities, we are only interested in the best\n",
    "        log_alpha_table[i, j] = np.max(path_max_log_prob)\n",
    "        # and we also want to store a pointer to the best\n",
    "        back_pointer_table[i, j] = np.argmax(path_max_log_prob)\n",
    "        return log_alpha_table[i, j]\n",
    "\n",
    "    # Let's get the index associated with -EOS-\n",
    "    #  which is the tag for the </s> symbol in sentence[-1]\n",
    "    eos_index = tagset.index('-EOS-')\n",
    "    # We want the last word in the sentence (</s>) to have the tag -EOS-\n",
    "    # thus we ask \"what's the probability of the best path that ends in\n",
    "    # -EOS-?\"\n",
    "    max_log_prob = log_alpha(n - 1, eos_index)\n",
    "\n",
    "    # Here we retrieve the backpointers for the best analysis\n",
    "    #  the best analisys has n tags\n",
    "    bwd_argmax = [None] * n\n",
    "    #  the last tag is the -EOS- symbol\n",
    "    bwd_argmax[-1] = eos_index\n",
    "    # Here we maintain the \"current tag\" c_i\n",
    "    c_i = eos_index\n",
    "    for i in range(n - 1, 0, -1):  # we go backwards from c_{n-1} to c_1\n",
    "        # and set the value of c_{i-1} for the current c_i\n",
    "        bwd_argmax[i - 1] = back_pointer_table[i, c_i]\n",
    "        # we need, of course, to update c_i\n",
    "        c_i = bwd_argmax[i - 1]\n",
    "\n",
    "    # Here we translate from ids back to actual tags (strings)\n",
    "    #  we leave the -EOS- symbol out, since it was just a convenience\n",
    "    #  and return both the tag sequence and the total log probability\n",
    "    return [tagset[c] for c in bwd_argmax[:-1]], max_log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bkHeST72vVA8"
   },
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10990,
     "status": "ok",
     "timestamp": 1520682636373,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110618989541510237728"
     },
     "user_tz": -60
    },
    "id": "nYro_nxlvVA-",
    "outputId": "95115b6a-e43d-4b02-f80f-3d0fb12ae733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n",
      "8.700521289904906e-05\n",
      "-207.70297815546238\n"
     ]
    }
   ],
   "source": [
    "# treebank_sents = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
    "treebank_training = list(treebank_sents[:3000])\n",
    "treebank_dev = list(treebank_sents[3000:3100])\n",
    "treebank_test = list(treebank_sents[3100:])\n",
    "print(len(treebank_test))\n",
    "\n",
    "treebank_hmm = HMMLM()\n",
    "treebank_hmm.estimate_model(treebank_training)\n",
    "\n",
    "print(treebank_hmm.joint_parameter('DET', 'NOUN', 'book'))\n",
    "sentence = [x for x, _ in treebank_dev[0]]\n",
    "tag_sequence = [c for _, c in treebank_dev[0]]\n",
    "print(treebank_hmm.log_joint(sentence, tag_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31933,
     "status": "ok",
     "timestamp": 1520682668612,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110618989541510237728"
     },
     "user_tz": -60
    },
    "id": "gXjsMaZcvVBC",
    "outputId": "6b206320-50d1-4932-d2b8-1ea6d943bc62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.864406779661017\n"
     ]
    }
   ],
   "source": [
    "def make_tag_sents(testset):\n",
    "    result = []\n",
    "    for sent in testset:\n",
    "        to_sent = []\n",
    "        for _, c in sent:\n",
    "            to_sent.append(c)\n",
    "        result.append(to_sent)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def make_word_sents(testset):\n",
    "    result = []\n",
    "    for sent in testset:\n",
    "        to_sent = []\n",
    "        for x, _ in sent:\n",
    "            to_sent.append(x)\n",
    "        result.append(to_sent)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def determine_viterbi_rec_accuracy(hmm, golden_std, test_set):\n",
    "    test_result = []\n",
    "    for sent in test_set:\n",
    "        viterbi_path, _ = viterbi_recursion(sent, hmm)\n",
    "        test_result.append(viterbi_path)\n",
    "\n",
    "    return(accuracy(golden_std, test_result))\n",
    "\n",
    "\n",
    "ptb_gold = make_tag_sents(treebank_test)\n",
    "sents_ptb = make_word_sents(treebank_test)\n",
    "\n",
    "lim = 2\n",
    "print(determine_viterbi_rec_accuracy(treebank_hmm,\n",
    "                                     ptb_gold[:lim],\n",
    "                                     sents_ptb[:lim]))\n",
    "# print(determine_viterbi_rec_accuracy(treebank_hmm, ptb_gold, sents_ptb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 447,
     "status": "ok",
     "timestamp": 1520682669114,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110618989541510237728"
     },
     "user_tz": -60
    },
    "id": "0ivzwbpRvVBE",
    "outputId": "8fc540fe-4d73-40f5-f5bc-1d8b14eec0e5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mine: (['DET', 'VERB', 'DET', 'NOUN', '.', 'CONJ', 'ADV', 'VERB'], -61.239278580821974)\n",
      "Recu: (['PRON', 'VERB', 'DET', 'NOUN', '.', 'CONJ', 'ADV', '.'], -62.86055666422245)\n",
      "Mine: (['DET', 'VERB', 'DET', 'NOUN', '.'], -31.94496736549541)\n",
      "Recu: (['PRON', 'VERB', 'DET', 'NOUN', '.'], -32.75258925965308)\n",
      "Mine: 0.8697916666666666\n",
      "Recu: 0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "def viterbi(sentence, hmm):\n",
    "    \"\"\"\n",
    "    Computes the best possible tag sequence for a given input\n",
    "    and also returns it log probability.\n",
    "\n",
    "    This implementation should NOT use recursion.\n",
    "\n",
    "    :returns: tag sequence, log probability\n",
    "    \"\"\"\n",
    "    sentence = hmm.preprocess_sentence(sentence,\n",
    "                                       bos=False,\n",
    "                                       eos=False)\n",
    "    n = len(sentence)\n",
    "    tagset = list(hmm.tagset())\n",
    "\n",
    "    # Fill in array, keys are tags, separated by spaces\n",
    "    V = [{} for _ in range(n)]\n",
    "    for tag in tagset:\n",
    "        V[0]['-BOS- ' + tag] = np.log(\n",
    "            hmm.joint_parameter('-BOS-', tag, sentence[0]))\n",
    "        #np.log(hmm.emission_parameter(tag, sentence[0]))\n",
    "    for i in range(1, n):\n",
    "        # Could prune\n",
    "        best_prev_tags = max(V[i - 1], key=V[i - 1].get)\n",
    "        prev_p = V[i - 1][best_prev_tags]\n",
    "        for tag in tagset:\n",
    "            V[i][best_prev_tags + ' ' + tag] = prev_p + np.log(\n",
    "                hmm.joint_parameter(best_prev_tags.split()[-1],\n",
    "                                    tag, sentence[i]))\n",
    "    best_tags = max(V[n-1], key=V[n-1].get)\n",
    "    return best_tags.split()[1:], V[n-1][best_tags]\n",
    "\n",
    "\n",
    "def determine_viterbi_own_accuracy(hmm, golden_std, test_set):\n",
    "    test_result = []\n",
    "    for sent in test_set:\n",
    "        viterbi_path, _ = viterbi(sent, hmm)\n",
    "        test_result.append(viterbi_path)\n",
    "\n",
    "    return(accuracy(golden_std, test_result))\n",
    "\n",
    "\n",
    "x = \"This is a sentence , but very bad.\".split()\n",
    "print(\"Mine:\", viterbi(x, treebank_hmm))\n",
    "print(\"Recu:\", viterbi_recursion(x, treebank_hmm))\n",
    "x = \"This is a book .\".split()\n",
    "print(\"Mine:\", viterbi(x, treebank_hmm))\n",
    "print(\"Recu:\", viterbi_recursion(x, treebank_hmm))\n",
    "lim = 6\n",
    "print(\"Mine:\", determine_viterbi_own_accuracy(treebank_hmm,\n",
    "                                              ptb_gold[:lim],\n",
    "                                              sents_ptb[:lim]))\n",
    "if lim > 20:\n",
    "    lim = 20  # mokerbad Wilker\n",
    "print(\"Recu:\", determine_viterbi_rec_accuracy(treebank_hmm,\n",
    "                                              ptb_gold[:lim],\n",
    "                                              sents_ptb[:lim]))\n",
    "\n",
    "# Unprofessional conclusion: the recursive version REALLY sucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRSvxq_OvVBH"
   },
   "source": [
    "## Running the experiments (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 196,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 632,
     "status": "error",
     "timestamp": 1520682669828,
     "user": {
      "displayName": "Bram Otten",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "110618989541510237728"
     },
     "user_tz": -60
    },
    "id": "yOOczklRvVBH",
    "outputId": "7ba79180-4112-4a4b-d332-8d6ed33903c1"
   },
   "outputs": [],
   "source": [
    "training_ids = [int(i) for i in open('training.ids') if i.strip()]\n",
    "development_ids = [int(i) for i in open('development.ids') if i.strip()]\n",
    "test_ids = [int(i) for i in open('test.ids') if i.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "02WT8AvdvVBJ"
   },
   "outputs": [],
   "source": [
    "ptb_training = [treebank_sents[i] for i in training_ids]\n",
    "ptb_development = [treebank_sents[i] for i in development_ids]\n",
    "ptb_test = [treebank_sents[i] for i in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Alpha = transition_alpha, beta = emission_alpha **\n",
      "\n",
      "** Results for alpha = 0.01 and beta = 0.01**\n",
      "   Perplexity: 12.3        Viterbi: 0.16\n",
      "\n",
      "** Results for alpha = 0.01 and beta = 0.1**\n",
      "   Perplexity: 12.4        Viterbi: 0.16\n",
      "\n",
      "** Results for alpha = 0.01 and beta = 1.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.16\n",
      "\n",
      "** Results for alpha = 0.01 and beta = 10.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.06\n",
      "\n",
      "** Results for alpha = 0.1 and beta = 0.01**\n",
      "   Perplexity: 12.2        Viterbi: 0.25\n",
      "\n",
      "** Results for alpha = 0.1 and beta = 0.1**\n",
      "   Perplexity: 12.4        Viterbi: 0.16\n",
      "\n",
      "** Results for alpha = 0.1 and beta = 1.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.16\n",
      "\n",
      "** Results for alpha = 0.1 and beta = 10.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.06\n",
      "\n",
      "** Results for alpha = 1.0 and beta = 0.01**\n",
      "   Perplexity: 12.1        Viterbi: 0.25\n",
      "\n",
      "** Results for alpha = 1.0 and beta = 0.1**\n",
      "   Perplexity: 12.4        Viterbi: 0.25\n",
      "\n",
      "** Results for alpha = 1.0 and beta = 1.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.16\n",
      "\n",
      "** Results for alpha = 1.0 and beta = 10.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.06\n",
      "\n",
      "** Results for alpha = 10.0 and beta = 0.01**\n",
      "   Perplexity: 12.1        Viterbi: 0.25\n",
      "\n",
      "** Results for alpha = 10.0 and beta = 0.1**\n",
      "   Perplexity: 12.4        Viterbi: 0.25\n",
      "\n",
      "** Results for alpha = 10.0 and beta = 1.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.25\n",
      "\n",
      "** Results for alpha = 10.0 and beta = 10.0**\n",
      "   Perplexity: 12.5        Viterbi: 0.16\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(12.312813482574477, 0.16129032258064516),\n",
       "  (12.496750944420171, 0.16129032258064516),\n",
       "  (12.567095003977059, 0.16129032258064516),\n",
       "  (12.576511540223452, 0.06451612903225806)],\n",
       " [(12.258362113537132, 0.25806451612903225),\n",
       "  (12.472661673087462, 0.16129032258064516),\n",
       "  (12.563145564208686, 0.16129032258064516),\n",
       "  (12.576089117725154, 0.06451612903225806)],\n",
       " [(12.189050799986951, 0.25806451612903225),\n",
       "  (12.439890058806414, 0.25806451612903225),\n",
       "  (12.557090696931997, 0.16129032258064516),\n",
       "  (12.575425812609847, 0.06451612903225806)],\n",
       " [(12.167223770991562, 0.25806451612903225),\n",
       "  (12.429994509805667, 0.25806451612903225),\n",
       "  (12.55512069213029, 0.25806451612903225),\n",
       "  (12.575206092161354, 0.16129032258064516)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def test_parameters(training_set, test_set,\n",
    "                    parameters_alpha, parameters_beta):\n",
    "\n",
    "    test_sents = make_word_sents(test_set)\n",
    "    test_tags = make_tag_sents(test_set)\n",
    "\n",
    "    result_array = []\n",
    "    print(\"** Alpha = transition_alpha, beta = emission_alpha **\\n\")\n",
    "\n",
    "    for alpha in parameters_alpha:\n",
    "        results = []\n",
    "        for beta in parameters_beta:\n",
    "            treebank_hmm = HMMLM(transition_alpha=alpha,\n",
    "                                 emission_alpha=beta)\n",
    "            treebank_hmm.estimate_model(training_set)\n",
    "            perp = log_perplexity(test_tags, treebank_hmm)\n",
    "            viterbi = determine_viterbi_own_accuracy(\n",
    "                treebank_hmm, test_tags, test_sents)\n",
    "            results.append((perp, viterbi))\n",
    "            print(\"** Results for alpha = \" + str(alpha)[:4] +\n",
    "                  \" and beta = \" + str(beta)[:4] + \"**\")\n",
    "            print(\"   Perplexity: \" + str(perp)[:4] + \"        \"\n",
    "                  \"Viterbi: \" + str(viterbi)[:4])\n",
    "            print()\n",
    "\n",
    "        result_array.append(results)\n",
    "\n",
    "    return result_array\n",
    "\n",
    "\n",
    "parameters_alpha = [0.01, 0.10, 1.00, 10.0]\n",
    "parameters_beta = [0.01, 0.10, 1.00, 10.0]\n",
    "lim = 2\n",
    "test_parameters(ptb_training[:lim], ptb_development[:lim],\n",
    "                parameters_alpha, parameters_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without limit:\n",
    "test_parameters(ptb_training[:lim], ptb_development[:lim],\n",
    "                parameters_alpha, parameters_beta)\n",
    "results = [[(53.448521686290697, 0.8919712793733682),\n",
    "            (47.330927607654615, 0.8864229765013055),\n",
    "            (41.96051297236022, 0.8560704960835509),\n",
    "            (41.161865555645363, 0.7682767624020888)],\n",
    "           [(53.445369099263594, 0.8919712793733682),\n",
    "            (47.329609438720318, 0.8864229765013055),\n",
    "            (41.96014643605119, 0.8560704960835509),\n",
    "            (41.161812748821752, 0.7682767624020888)],\n",
    "           [(53.414116822901967, 0.8919712793733682),\n",
    "            (47.316515993240216, 0.8864229765013055),\n",
    "            (41.956502095575537, 0.8560704960835509),\n",
    "            (41.161288040286323, 0.7682767624020888)],\n",
    "           [(53.126548139688857, 0.8913185378590078),\n",
    "            (47.193792971447294, 0.8870757180156658),\n",
    "            (41.922031064051346, 0.8616187989556136),\n",
    "            (41.156354423292662, 0.7689295039164491)]]\n",
    "\n",
    "check_alpha = [10.0]\n",
    "check_beta = [10.0, 1.0]\n",
    "check2_alpha = [0.01]\n",
    "check2_beta = [0.01]\n",
    "\n",
    "test_parameters(ptb_training, ptb_test,\n",
    "                check_alpha, check_beta)\n",
    "\n",
    "test_parameters(ptb_training, ptb_test,\n",
    "                check2_alpha, check2_beta)\n",
    "\n",
    "# Prepare for the KeyboardInterrupt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gvOx-WfvVBO"
   },
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  alpha    beta     ppl    vit\n",
      "-------  ------  ------  -----\n",
      "   0.01    0.01  53.449  0.892\n",
      "   0.01    0.1   47.331  0.887\n",
      "   0.01    1     41.961  0.856\n",
      "   0.01   10     41.162  0.768\n",
      "   0.1     0.01  53.445  0.892\n",
      "   0.1     0.1   47.33   0.886\n",
      "   0.1     1     41.96   0.856\n",
      "   0.1    10     41.162  0.768\n",
      "   1       0.01  53.414  0.892\n",
      "   1       0.1   47.317  0.886\n",
      "   1       1     41.957  0.856\n",
      "   1      10     41.161  0.768\n",
      "  10       0.01  53.127  0.891\n",
      "  10       0.1   47.194  0.887\n",
      "  10       1     41.922  0.862\n",
      "  10      10     41.156  0.769\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "results = [[0.01, 0.01, 53.449, 0.892], [0.01, 0.1, 47.331, 0.887], [0.01, 1.0, 41.961, 0.856], [0.01, 10.0, 41.162, 0.768],\n",
    "           [0.1, 0.01, 53.445, 0.892], [0.1, 0.1, 47.330, 0.886], [\n",
    "               0.1, 1.0, 41.960, 0.856], [0.1, 10.0, 41.162, 0.768],\n",
    "           [1.0, 0.01, 53.414, 0.892], [1.0, 0.1, 47.317, 0.886], [\n",
    "               1.0, 1.0, 41.957, 0.856], [1.0, 10.0, 41.161, 0.768],\n",
    "           [10.0, 0.01, 53.127, 0.891], [10.0, 0.1, 47.194, 0.887], [10.0, 1.0, 41.922, 0.862], [10.0, 10.0, 41.156, 0.769]]\n",
    "headers = ['alpha', 'beta', 'ppl', 'vit']\n",
    "print(tabulate(results, headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEaCAYAAADg2nttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XecXFX5x/HPN9k0WgIkgJCEBIjSCbKAFBFBaSJBemgCEQQpokj90ZsIUqQbEYKAhCYCAiJVEEHZAEFDM4aSSDGBBAKhpDy/P85dM5nM7Mxmd/Zu+b5fr3nt3Du3PHPv7Dxzzrn3HEUEZmZmTemWdwBmZtb+OVmYmVlFThZmZlaRk4WZmVXkZGFmZhU5WZiZWUVOFrbIJA2W9JGk7k0sE5JWa8u4qiHpfknfzTuOQpLGSDo77zgaSVpe0uOSZkq6sJnrDsnOfV1rLtvWJD0m6XtlXjtd0o1tHVNe2t3J6QgkPQasB6wQEZ/lHE5uIuJNYInG6ey43BgR1+QWVJUiYvu8Y+gADgGmAUuFb8hqVZJOB1aLiH3zjqVaLlk0k6QhwFeBAHZq4307uVfBx6nVrAy86ERh4GSxKPYHngbGAAtUY0jqI+lCSW9I+kDSXyT1yV7bXNJfJc2QNFnSAdn8BYq5kg6Q9JeC6ZB0uKR/Af/K5v0i28aHksZJ+mrB8t0lnSTp31n1wThJgyRdUVyVIOkeSUcXv0FJZ0i6LHveQ9LHks4veI+fSlq6sPpA0jmkJHp5VjV1ecEmvyHpX5KmZ3GoxD5XlPSJpGUK5q0vaVoWw6qSHpH0XjbvJkn9CpZ9XdLxkl4APpZ0rKQ7ivZxmaRLio974zGX9PMsxtckbV+w3tCC6piHsvdQsvpB0kuSdiyYrsvi/XI2fZukd7LPx+OS1iqznQU+B9m8/1XpSeqVxfumpHclXV3wWesv6Q/ZZ+19SU9IKvm/LmlTSc9k8TwjadNs/hjS5/u47Hx+o8S635L0XPY5nKz0a7mk7Hj/VNLfs33dVXiuM/tk72eapP8rWHcjSU9l7+dtSZdL6tnEvsoeY6Wqvisk3Zudz79JWrXg9W9Kejlb93Jgoc9qkd6Sbsm29ayk9Qq2taKkOyRNzT5TR2XztwNOAvbMju34bP6B2ednpqRJkr5fYd9tKyL8aMYDmAj8ANgAmA0sX/DaFcBjwEpAd2BToBcwGJgJjAR6AMsCw7N1HgO+V7CNA4C/FEwH8CCwDNAnm7dvto064BjgHaB39tqxwD+AL5E+6Otly24EvAV0y5brD8wqjL9gn1sB/8iebwr8G/hbwWvjs+dDsvjqSr2Xgvj/APTLjsNUYLsyx/YR4OCC6QuAq7PnqwHfzI7nAOBx4JKCZV8HngcGAX2ALwAfA/2y1+uA/wIbFMeaHfPZwMHZeTssO1bKXn8K+DnQE9gc+JBU3VbqPZwK3FQw/S3g5YLpg4Als/dxCfB8wWtjgLNLfQ4KjuVq2fNLgLuzz8WSwD3AT7PXfgpcTfqs9SAlcZWIdRlgOrBfdnxGZtPLFsdT5r1uCaxD+tG5LvAusHMTn43/AGsDiwN3NB7DgmV/lZ279YDPgDWy1zcAvpLFOAR4CTi6ibgqHeP3Sf8PdcBNwNiC/4kPgd2y4/YjYA5Fn+mCbZ2efW4al/8J8Fr2vBswLvs89ARWASYB2xase2PR9r4FrEr6v/0a6f/zy3l/5/0vvrwD6EgP0hfFbKB/Nv0y8KPseTfgE2C9EuudCNxZZpuPUTlZbFUhrumN+wVeAUaUWe4l4JvZ8yOA+8os1wf4lJRkTiD9CppCap84A7g0W67UF0KpZLF5wfStwAll9vs94JHsuYDJwBZllt0ZeK5g+nXgoKJl7idLPsCOpCqVhY57dswnFry2WBb3CqQENwdYrOD1G4v/0QteW430w2CxbPom4NQyy/bL9tM3mx5DFckiOzYfA6sWvLYJ8Fr2/EzgLrLE0sTnZj/g70XzngIOKI6nyv+PS4CLm/hsnFew7JrA56Tk3LjswILX/w7sVWY/R1Pm/6nKY3xNwes7kCVzslqDgtdE+tw3lSwKl+8GvE1KzhsDbxYtfyJwXcG6JT9DBcv/Hvhhtce/1g9XQzXPd4E/RcS0bPq3zK+K6g/0Jv0KLzaozPxqTS6ckHRMVlz9QNIMoG+2/0r7up5UKiH7e0OphSLiE6CB9OtmC+DPwF+BzbJ5f25m/O8UPJ9FQaN4kduBTSStmO03gCcAJC0naayk/0j6kPSF3b9o/clF01W93+IYI2JW9nQJYEXg/YJ5pfbzPxExkZSUvy1pMVK71m+z99Bd0nlKVYQfkhIcJd5HJQNICW1cVjUzA/hjNh9SiWwi8KesOuOEMttZEXijaN4bpJJxRZI2lvRoVs3yAXBohfdSeNzeIP0CL1y+5OdE0hezarV3suN2brn9VHmMy30eVyyMMdI3dtlzXfyeImIeKbmsSGrvWbHx/GTn6CRg+XIbkrS9pKezqsMZpETW3M9GzThZVCmrD94D+Fr2oX2HVExdL6unnEb6Nb5qidUnl5kP6RfiYgXTK5RY5n8NjErtE8dnsSwdEf2AD5hft9rUvm4ERmTxrkH65VLOn0lVTusDz2TT25KK74+XWadFDaERMQP4E+m97Q3cnP3DQqpaCWDdiFiK9OVfXJ9cvP/fA+tKWptUsrhpEcJ6G1gm++JvNKjCOjeTqnRGkEozE7P5e2fzvkFK8EOy+aXqxRf4XEgq/FxMI5Vi14qIftmjb0QsARARMyPimIhYBfg28GNJW5fYx1ukL7VCg0nVRdX4LakqbFBE9CVVfTVVx1943AaTSunTyixb6CpSKX5Ydu5PamI/zTnGxd4ujFGSqHyuC5fvBgwkHdfJpJJev4LHkhGxQ7b4Ap9VSb1IVXM/J1UN9wPuqzLuNuFkUb2dgbmk4vPw7LEG6Zfv/tmvimuBi7KGre6SNsk+BDeRGnn3UGrwXFbS8Gy7zwO7SFpMqfFyVIU4liRVi0wF6iSdCixV8Po1wFmShilZV9KyABExhfTFfwNwR1aCKOfPpGL5ixHxOVm1DekfYGqZdd4l1c22xG+z/e6aPW+0JPARMEPSSqS2mSZFxKek0spvSdUtbzY3mIh4g1TKOl1ST0mbkL6AmzIW2IbU9lH8Hj4D3iMlgnOb2MZ4YC1JwyX1JlVbNMY0j1S/f7Gk5QAkrSRp2+z5jpJWy77sPiR9bueW2Md9wBcl7Z19Lvckfb7/UOH9Fb6f9yPiU0kbkb6om7KvpDWzxHsmcHtElIqr1H4+BD6StDrpuDa1bLXHuNi9pGO+i9IVdUdR+sdboQ0Klj862/fTpGq0D5UuuuiTfR+sLWnDbL13gSGaf+FBT1Iby1RgjtIFFts0I/aac7Ko3ndJ9Y1vRsQ7jQ/gctJVHHWkBq5/kL6Q3wd+RmpQfpNUpDwmm/88qREP4GJS3e27pGqTSr9+HyDVxb9KKsp/yoJF5YtI7QJ/Iv2D/ZrUBtHoelKjZFNVMpCqnfowvxTxYravcqUKgF8AuyldUXRphe2XczcwDHg3IsYXzD8D+DKpFHUv8Lsqt1ft+23KPqQ2gfeAs4FbSF8KJUXE26S6/02zZRv9hnTO/kM6nk83sY1XSV+oD5GugvtL0SLHk6qans6qWx4iXdQA6fg9REquTwFXRsRjJfbxHqnEdUz23o4DdiyoZq3kB8CZkmaSGnJvrbD8DaQ2g3dIVbZHVbmfn5AS0UxSkryliWWrPsbFsve9O3Ae6XgMA56ssNpdwJ7Mv1Bgl4iYnSXBb5N+VL5GKkFdQyrtANyW/X1P0rMRMZN0PG7NtrU36X+h3Wi82sO6CElbkKqjhmS/UDs1SYNJVRgrRMSHrbTNW0iNoqe1xva6AnWgGzatNJcsuhBJPYAfkq4G6QqJohvwY9KlkYucKCRtqHSfR7fsGvkRNN3eY9bp+E7XLkLSGqS69/HAgTmHU3OSFidV7b0BbNfCza1AqvZalnS1y2ER8VwLt2nWobgayszMKnI1lJmZVeRkYWZmFXWaNov+/fvHkCFD8g7DzKxDGTdu3LSIGFBpuU6TLIYMGUJDQ0PeYZiZdSiSirt8KcnVUGZmVpGThZmZVeRkYWZmFTlZmJlZRU4WZmZWkZOFmZlV1GkunV1UH7wxnRevfoK+fWGppdJj8SWgu9OoWWl1da336OZ/tI6iyyeLyY9MZJPzRuQdhlnXJLVu8unRo3W3V+uH2s1AeBV1+WSxyo5r8vJN45gxg4Ue06cXTc+AOXNKb6euDpbuB/2aeCy99ILTvXu37Xs1a7EImDs3/SO0h8fs2fDJJ4u+ft66dWudRLfllnBCuaHWW0eXTxaLDVic1ff+clXLRsDMmTBtWnpMnTr/eeHjxWkwbQpMex7eey+tV3Lfi0H//gs+BgxYeF7jY9ll0+fJzFpBBMybl1+Sa43tfPpp+jtzZs0PV5dPFs0hzW/XWKXKkabnzk0llFJJpTjpTJyY/n7YxDA9ffs2nVCKE06/fq4WNitJgu7d06NXr7yjafecLGqse/f5X9zV+vzzVCKpVIL5z39g/Pj0+qeflt5Wt26pRNKcEswSS3SoqlQzawNOFu1Qz57whS+kRzUiYNas6kovr74Kf/1rej53bunt9erVdMmlOOEsu6zbX8w6OyeLTkCCxRdPj5VXrm6dCPjgg9IJpfjx3HPp7/vvl9/eEks0r/SyzDKpXc7MOgb/u77/Pjz4YG0uy2vHjQXS/KuyVlutunXmzEmHq5oSzMsvp78ffVR+/0sv3XTJZcMNYe21W+89m+Wu8Wqy1mrgbnwMHAibbFLT0J0sJk6EvfaqzbZb+xrynK89r6urY7m6OpbrUQeD6mBo5WvIP/10wfaXciWYN96AcePSa59/Pv8Q7rQTnHxyShzWCbT2FUit/aVb60e5ut+W2nNPJ4uaW2cdePHF9vshbLw0blH+ifLWrRu96+pYKXtUTEjL1xEr1TFPdXw+r453pnZj8n1i5t3w/DIwZAj065v3m+riIlr+mc5b9+4t++HUu3f7+1HXr1/ND5uTRZ8+sMYaeUfR+vK8hrwFD82ZQ/fZs+kzezZDB81l0Irw9lswZQq88GxKFoMHQ99+4Au2ctKzZ7pJKO8S86J84Xbv7kv9FpGTRWfVSa4hrwMGAct8DL/8JVxwAbzzD9h0UzjlFNh2W//vm7WF9tsCa1Zg8cXhxz+G116Dyy+HyZNh++1ho43grrvK3yVvZq3DycI6lN694fDD03UJv/pVujpr551h+HC47bZU82Zmrc/Jwjqknj3he9+DV16B66+Hzz6DPfZIl9reeGP7aEc160ycLKxDq6uD/feHCRNg7NjURLPffrD66nDttQtehmtmi66myULSdpJekTRR0kL950oaLOlRSc9JekHSDtn8HpKul/QPSS9JOrGWcVrH1717utR8/Hj43e9Sh4ujRsGwYXDVVeX7zjKz6tQsWUjqDlwBbA+sCYyUtGbRYicDt0bE+sBewJXZ/N2BXhGxDrAB8H1JQ2oVq3Ue3brBd74DDQ1w772w4orwgx/AqqvCJZekPrTMrPlqWbLYCJgYEZMi4nNgLFA8JF0AS2XP+wJvFcxfXFId0Af4HGii426zBUmwww6p08SHHkoljB/9CIYOhfPPb5Pu/806lVomi5WAyQXTU7J5hU4H9pU0BbgPODKbfzvwMfA28Cbw84hoohs7s9Ik2HpreOwxePzxdNXU8cenu8HPOiuNgGhmldUyWZS6Var4aviRwJiIGAjsANwgqRupVDIXWBEYChwjaaHhhiQdIqlBUsPUqVNbN3rrdL76VXjgAXj66XRT36mnpl56Tzkl9V9lZuXVMllMId1822gg86uZGo0CbgWIiKeA3kB/YG/gjxExOyL+CzwJ1BfvICJGR0R9RNQPGDCgBm/BOqONN4Z77oFnn4VvfhPOPjsljeOOg3ffzTs6s/aplsniGWCYpKGSepIasO8uWuZNYGsASWuQksXUbP5WShYHvgK8XMNYrQtaf324/Xb45z9T77YXXpiqp374wzQKoZnNV7NkERFzgCOAB4CXSFc9TZB0pqSdssWOAQ6WNB64GTggIoJ0FdUSwD9JSee6iHihVrFa17bWWvDb38JLL6Xe6q+4Io2xfthh8PrreUdn1j4oOkmnOvX19dHQ0JB3GNYJvPYanHceXHdd6nNqv/3gpJOqHyTKrCORNC4iFqrmL+Y7uM2KDB2aeridNCmVLm6+Gb70Jdh33zT0iVlX5GRhVsbAgXDppamk8eMfw513pr6ndt893Slu1pU4WZhVsMIKaRyNN96AE09Ml98OHw4jRsAzz+QdnVnbcLIwq1L//nDOOSlpnHEGPPFEGk9ju+3gySfzjs6stpwszJpp6aXTDX2vv54awp99FjbfHL7+dXjkEQ/EZJ2Tk4XZIlpqqdR1yGuvwUUXpbE1tt46JY7773fSsM7FycKshRZfPHVSOGlSukdj8uTUiWHjkK8evc86AycLs1bSu3fqDr14yNf114dbb4W5c/OO0GzROVmYtbLCIV9/85s05Ouee3rIV+vYnCzMaqSuLt39PWEC3HIL9Ogxf8jXX//aQ75ax+JkYVZj3bvDHnvA88+nG/v69k0lj2HD4MorPeSrdQxOFmZtpFu31IbR0AD33QcrrQSHH+4hX61jcLIwa2MSbL99upHv4Yfhi19MV1MNGQI/+5mHfLX2ycnCLCcSbLUVPPpouht8/fXhhBM85Ku1T04WZu3A5punPqf+9jfYbLP5Q76efDJMm5Z3dGZOFmbtykYbwd13w3PPpSFfzzknlTSOPRbeeSfv6Kwrc7Iwa4eGD58/5OuIEak7kaFDPeSr5cfJwqwdW2stuOkmePllGDkyXWq7yipw6KEe8tXalpOFWQcwbBhcey38619w4IFpyNdhw+Cgg9I8s1pzsjDrQIYMgauvhn//O/VDdfPN6Y7wffbxkK9WW04WZh3QwIHwi1/MH/L1rrtS31O77ZbuFDdrbU4WZh1Y45Cvr78OJ50EDz6Y7tfYaSf4+9/zjs46E0UnGaGlvr4+Ghoa8g7DLFczZsBll8HFF8P06bDNNnDKKek+DusEIlLf9++8s+Bj6FDYZZdF2qSkcRFRX3G5WiYLSdsBvwC6A9dExHlFrw8Grgf6ZcucEBH3Za+tC/wSWAqYB2wYEWW7XHOyMJtv5sx05dSFF8LUqfC1r6WksdVW6c5xa2dmzVo4ARQ+3n47/X33XZg9e+H1d9sNbrttkXade7KQ1B14FfgmMAV4BhgZES8WLDMaeC4irpK0JnBfRAyRVAc8C+wXEeMlLQvMiIiyw8c4WZgtbNYsGD0azj8/fd9ssklKGttt56RRc3Pnpkxd6ku/+PHhhwuvL8Fyy6W6xuLHF76w4PRSSy3yCa02WdQt0tarsxEwMSImZQGNBUYAhddsBKnkANAXeCt7vg3wQkSMB4iI92oYp1mntdhicPTR6b6M666D885LQ75usEHqSmSnnVJvuFaliPTFXk0pYOrU0mPqLrnk/C/74cPLJ4P+/dOgKO1ELSNZCZhcMD0F2LhomdOBP0k6Elgc+EY2/4tASHoAGACMjYjzi3cg6RDgEIDBgwe3avBmnUnv3nDYYTBqFNxwA5x7LnznO7DOOilp7LprGnejy/r881TFU6kE8M478MknC69fVzf/i37QINhww4V//a+wAiy/fBq0vQOqZbIoVSYqrvMaCYyJiAslbQLcIGntLK7NgQ2BWcDDWVHp4QU2FjEaGA2pGqq134BZZ9OzZ0oY3/0ujB2b+p7ac890r8ZJJ6W7xNvRj9mWmTevdGNwqYTw/vult7HssvO/6DfdtHxV0NJLd/oiWi0/FlOAQQXTA5lfzdRoFLAdQEQ8Jak30D9b988RMQ1A0n3Al4GHMbMWq6uDffdNyeGOO+Dss2H//eH00+HEE9Pznj3zjrKMwsbgpkoA5RqDe/ee/0W/+uqw5Zalq4KWX74dH4S2V8sG7jpSA/fWwH9IDdx7R8SEgmXuB26JiDGS1iAlg5VIV0c9TCpdfA78Ebg4Iu4ttz83cJstunnz4J570jga48bB4MFw/PGpO5HevdsggDlzFm4MLpcQSo0O1a1b6cbgUlVBSy7p1v0CuV8NlQWxA3AJ6bLYayPiHElnAg0RcXd2BdSvgCVIVVTHRcSfsnX3BU7M5t8XEcc1tS8nC7OWi0jjapx1Fvz1r+m79thj4fvfT43lzd5YY2NwUyWAt99OiaLUd1HfvqV/9Rcng/79u3ijy6JrF8miLTlZmLWeiDSC31lnwWOPwYABcMwxqT+qJXt+tmBjcFNVQp+WuDWqR4/Kv/4bq4GanaGsuZwsqvXcc+k2VzMrafZs+HhW+ttTs+kbH5ResH//6u4JWHppVwO1I+3hPouOYZllYI898o7CrN3qQWpEfPdduO2+7sxacjkOPW0Feg4uSAbLLZdKDNZpOVmsvDJccUXeUZi1e8sDgx5Id3+/MgGu+EHeEVlb6twXBptZq9p229Ql+pVXpm7RretwsjCzZjn33NQN+kEHeTzwrsTJwsyapVevNELfp5/Cfvul/vKs83OyMLNm+9KX4PLL0+W15y/Ua5t1Rk4WZrZIDjgg9St1yinw9NN5R2O15mRhZotEgquvTuOB7703fFDm9gvrHJwszGyR9esHv/0tvPlmuru7k9zjayU4WZhZi2y6KZx2WkoaN9yQdzRWK04WZtZiJ50EW2wBhx8OEyfmHY3VgpOFmbVY9+5w442px4+RI9PAc9a5OFmYWasYNAiuuQYaGtIVUta5OFmYWavZZZc09sX558ODD+YdjbUmJwsza1UXXQRrrpmGZp06Ne9orLU4WZhZq1pssdQdyPTpcOCBvpy2s3CyMLNWt+66cMEFcO+9cNlleUdjrcHJwsxq4ogjYMcd0xje48fnHY21lJOFmdWEBNdeC8suC3vtBbNm5R2RtYSThZnVzIAB6a7uV16BH/0o72isJZwszKymtt4ajjsORo+GO+7IOxpbVBWThaQjJC3dFsGYWed01lmw4Ybwve+lTget46mmZLEC8IykWyVtJ0nVbjxb/hVJEyWdUOL1wZIelfScpBck7VDi9Y8k/aTafZpZ+9OjR7qcds4c2Hdfj67XEVVMFhFxMjAM+DVwAPAvSedKWrWp9SR1B64AtgfWBEZKWrNosZOBWyNifWAv4Mqi1y8G7q/ifZhZO7fqqnDllfDEE3DOOXlHY81VVZtFRATwTvaYAywN3C6pqQEVNwImRsSkiPgcGAuMKN40sFT2vC/wVuMLknYGJgETqonRzNq//faDffaBM86AJ5/MOxprjmraLI6SNA44H3gSWCciDgM2AHZtYtWVgMkF01OyeYVOB/aVNAW4Dzgy2+fiwPHAGRViO0RSg6SGqe5XwKxDuPJKGDIkja43Y0be0Vi1qilZ9Ad2iYhtI+K2iJgNEBHzgB2bWK9U20bxjf8jgTERMRDYAbhBUjdSkrg4Ij5qKrCIGB0R9RFRP2DAgCreipnlbaml0kBJb72VOh10dyAdQzXJ4j7g/cYJSUtK2hggIl5qYr0pwKCC6YEUVDNlRgG3Ztt6CuhNSk4bA+dLeh04GjhJ0hFVxGpmHcDGG6crpG69Fa67Lu9orBrVJIurgMJf+B9n8yp5BhgmaaiknqQG7LuLlnkT2BpA0hqkZDE1Ir4aEUMiYghwCXBuRFxexT7NrIM47jjYais48kh4+eW8o7FKqkkWyhq4gf9VP9VVWiki5gBHAA8AL5Guepog6UxJO2WLHQMcLGk8cDNwQOG+zKzz6tYt3d3dp08aXe+zz/KOyJqiSt/Nkn4HPMb80sQPgK9HxM61Da156uvro6GhIe8wzKyZ7rkHdtopdQdy0UV5R9P1SBoXEfWVlqumZHEosCnwH1I7xMbAIS0Lz8ws+fa34fDD4eKL4Y9/zDsaK6diyaKjcMnCrOP65BPYaCP473/hhRdg+eXzjqjrqLZkUbHtQVJv0lVLa5EaoAGIiINaFKGZWaZPHxg7Furr4bvfhfvuS20a1n5UczpuIPUPtS3wZ9IlsDNrGZSZdT1rrZWqoh54AC65JO9orFg1yWK1iDgF+Dgirge+BaxT27DMrCv6/vdh553hhBNg3Li8o7FC1SSL2dnfGZLWJvXhNKRmEZlZlyXBNdfAcsuly2k/arIPB2tL1SSL0dl4FieTbqp7EfhZTaMysy5r2WXhxhth4kQ46qi8o7FGTSaLrJ+mDyNiekQ8HhGrRMRyEfHLNorPzLqgLbeEk05KXYHcckve0RhUSBbZ3druk8nM2txpp8FXvgKHHAKvv553NFZNNdSDkn4iaZCkZRofNY/MzLq0Hj1S77SQujOfMyffeLq6apLFQcDhwOPAuOzhu9/MrOaGDoVf/hKeegrOPDPvaLq2ajoEHNoWgZiZlbLXXunei7PPhq23hq99Le+IuqZq7uDev9T8iPhN64djZrawyy5Lw7Duuy+MHw/LuCK8zVVTDbVhweOrpKFQd2pqBTOz1rTEEnDzzfDuu/C973l0vTxUTBYRcWTB42BgfaBn7UMzM5tvgw3g3HPhzjth9Oi8o+l6FqWrrlnAsNYOxMyskh//GLbZJo198eKLeUfTtVTTZnEP0Fjo6wasSTZutplZW+rWDa6/HtZdNzV8//3v0Lt35fWs5SomC+DnBc/nAG9ExJQaxWNm1qQVVkgJY4cd0jjel16ad0RdQzXVUG8Cf4uIP0fEk8B7kobUNCozsyZsvz0cfXS6Suqee/KOpmuoJlncBswrmJ6bzTMzy81558Hw4XDggfDWW3lH0/lVkyzqIuLzxonsua+GMrNc9eqVLqf95BPYf3+YN6/yOrboqkkWUyX9774KSSOAabULycysOquvDr/4BTz8MFxwQd7RdG7VJItDgZMkvSnpTeB44Pu1DcvMrDqjRsHuu8PJJ6ero6w2qrkp798R8RXSJbNrRcSmETGxmo1L2k7SK5ImSjqhxOuDJT0q6TlJL0jaIZv/TUnjJP0j+7tVc9+YmXUNUrpJb8UVU++0M2fmHVHnVDFZSDpXUr+I+CgiZkpaWtLZVazXHbgC2J6UaEZKWrPL0b20AAAUXklEQVRosZOBWyNifWAv4Mps/jTg2xGxDvBd4Ibq35KZdTX9+qXuzF97DQ4/PO9oOqdqqqG2j4gZjRMRMR3YoYr1NgImRsSkrFF8LDCiaJkAlsqe9wXeyvbxXEQ0Xt8wAegtqVcV+zSzLmqzzeDUU+GGG9KwrNa6qkkW3Qu/qCX1Aar54l4JmFwwPSWbV+h0YF9JU4D7gCNLbGdX4LmI+Kz4BUmHSGqQ1DB16tQqQjKzzuz//g823xwOOwz+/e+8o+lcqkkWNwIPSxolaRTwIHB9FeupxLziviJHAmMiYiCptHJDNu532oC0FvAzyjSoR8ToiKiPiPoBAwZUEZKZdWZ1dXDTTenv3nvD7Nl5R9R5VNPAfT5wNrAGqe3hj8DKVWx7CjCoYHogWTVTgVFk/UxFxFNAb6A/gKSBwJ3A/hHh3whmVpXBg+FXv0pXRp16at7RdB7V9jr7Duku7l2BrYGXqljnGWCYpKGSepIasO8uWubNbHtIWoOULKZK6gfcC5yYdTFiZla13XaDgw+Gn/0MHnkk72g6h7LJQtIXJZ0q6SXgclL7gyLi6xFxeaUNR8Qc4AjgAVJyuTUiJkg6s+Amv2OAgyWNB24GDoiIyNZbDThF0vPZY7mWvFEz61ouvhi+9KU0ut4030bcYooyQ05Jmgc8AYxqvK9C0qSIWKUN46tafX19NDQ05B2GmbUj48fDRhvBttvCXXelezJsQZLGRUR9peWaqobalVT99KikX0namtKN1mZm7dJ668H556eeaa+4Iu9oOrayySIi7oyIPYHVgceAHwHLS7pK0jZtFJ+ZWYscdVQa++InP4EXXsg7mo6rmquhPo6ImyJiR9IVTc8DC3XdYWbWHklw3XXpLu+RI2HWrLwj6piaNQZ3RLwfEb+MCPfVZGYdxnLLwW9+k8btPuaYvKPpmJqVLMzMOqpttoFjj4Wrr4Y778w7mo7HycLMuoyzz4b6+tSt+eTJlZe3+ZwszKzL6Nkz9U77+eew334wd27eEXUcThZm1qUMG5Yuo/3zn+GnP807mo7DycLMupz9909XRp1+Ojz1VN7RdAxOFmbW5Uhw1VUwaFDqnfaDD/KOqP1zsjCzLqlvX7j55tTQfeihUKbnI8s4WZhZl/WVr8CZZ8LYsXB9NaP0dGFOFmbWpR1/PGy5JRxxBLz6at7RtF9OFmbWpXXvnsbs7tUrNXp/ttAAzgZOFmZmrLQSXHstPPtsGsfbFuZkYWYGjBgBhx0GF14IDzyQdzTtj5OFmVnmwgthrbXgu9+F//4372jaFycLM7NMnz7pctoZM+CAA2DevLwjaj+cLMzMCqyzDlx0Edx/P1x6ad7RtB9OFmZmRQ47LLVhHH88PPdc3tG0D04WZmZFJLjmGujfP11O+/HHeUeUPycLM7MS+vdP91+8+ir88Id5R5M/JwszszK+/nU44QT49a/httvyjiZfNU0WkraT9IqkiZJOKPH6YEmPSnpO0guSdih47cRsvVckbVvLOM3MyjnjDNh4Yzj4YHjjjbyjyU/NkoWk7sAVwPbAmsBISWsWLXYycGtErA/sBVyZrbtmNr0WsB1wZbY9M7M21aNHGl1v3jzYZx+YMyfviPJRy5LFRsDEiJgUEZ8DY4ERRcsEsFT2vC/wVvZ8BDA2Ij6LiNeAidn2zMza3CqrwNVXw5NPpnG8u6JaJouVgMIh0adk8wqdDuwraQpwH3BkM9ZF0iGSGiQ1TJ06tbXiNjNbyN57pxH2zjoLnngi72jaXi2ThUrMKx5eZCQwJiIGAjsAN0jqVuW6RMToiKiPiPoBAwa0OGAzs6ZcfnkqZeyzD0yfnnc0bauWyWIKMKhgeiDzq5kajQJuBYiIp4DeQP8q1zUza1NLLpnaL95+OzV4d6XR9WqZLJ4BhkkaKqknqcH67qJl3gS2BpC0BilZTM2W20tSL0lDgWHA32sYq5lZVTbcEM45B+64I92411XULFlExBzgCOAB4CXSVU8TJJ0paadssWOAgyWNB24GDohkAqnE8SLwR+DwiJhbq1jNzJrjJz+Bb3wj3az30kt5R9M2FJ2kHFVfXx8NDQ15h2FmXcTbb8O666aBk55+Gnr3zjuiRSNpXETUV1rOd3CbmS2CL3wBxoyB8ePTXd6dnZOFmdki+ta34Kij4Be/gHvvzTua2nKyMDNrgZ/9DNZbLw2W9PbbeUdTO04WZmYt0Lt3Gl3v44/TTXuddXQ9JwszsxZaYw245BJ46KE0jndn5GRhZtYKDj4YdtkFTjoJOuOFmU4WZmatQIJf/QpWWCGNrjdzZt4RtS4nCzOzVrLMMnDTTTBpEhx5ZOXlOxInCzOzVrTFFnDyyXD99akfqc7CycLMrJWdcgpsthkcemgqZXQGThZmZq2sri5VR3XrlsbBmD0774hazsnCzKwGVl4ZRo+Gv/0NTj8972hazsnCzKxG9tgDDjoIfvpTePTRvKNpGScLM7MauvRSGDYM9tsP3nsv72gWnZOFmVkNLb44jB0LU6fCqFEdd3Q9Jwszsxpbf3047zy46y64+uq8o1k0ThZmZm3ghz+E7baDH/8Y/vnPvKNpPicLM7M20K1bGiypb1/Yay/45JO8I2oeJwszszay/PLpzu4JE9I43h2Jk4WZWRvadttUFXXllakNo6NwsjAza2PnnpsavQ86CP7zn7yjqY6ThZlZG+vVK11O+9ln6f6LuXPzjqgyJwszsxx88Ytw2WXpzu7zz887mspqmiwkbSfpFUkTJZ1Q4vWLJT2fPV6VNKPgtfMlTZD0kqRLJamWsZqZtbUDDoA990y91D79dN7RNK1myUJSd+AKYHtgTWCkpDULl4mIH0XE8IgYDlwG/C5bd1NgM2BdYG1gQ+BrtYrVzCwPUrpJb+DA1DvtBx/kHVF5tSxZbARMjIhJEfE5MBYY0cTyI4Gbs+cB9AZ6Ar2AHsC7NYzVzCwX/fqlQZLefBN+8IP22x1ILZPFSsDkgukp2byFSFoZGAo8AhARTwGPAm9njwci4qUS6x0iqUFSw9SpU1s5fDOztrHppnDaaSlp3HBD3tGUVstkUaqNoVzO3Au4PSLmAkhaDVgDGEhKMFtJ2mKhjUWMjoj6iKgfMGBAK4VtZtb2TjopDcl6+OEwcWLe0SyslsliCjCoYHog8FaZZfdifhUUwHeApyPio4j4CLgf+EpNojQzawe6d4cbb4QePWDkSPj887wjWlAtk8UzwDBJQyX1JCWEu4sXkvQlYGngqYLZbwJfk1QnqQepcXuhaigzs85k0CD49a+hoSFdIdWe1CxZRMQc4AjgAdIX/a0RMUHSmZJ2Klh0JDA2YoFmnduBfwP/AMYD4yPinlrFambWXnznO/D976d7Lx58MO9o5lO016b3Zqqvr4+Ghoa8wzAza7FZs2DDDeH99+GFF6CWTbKSxkVEfaXlfAe3mVk7s9hicPPNMH06HHhg+7ic1snCzKwdWndduOACuPfe1C1I3pwszMzaqSOOgB13hGOPhfHj843FycLMrJ2S4LrrYNll0+h6s2blF4uThZlZO9a/f7qr+5VX4Ec/yi8OJwszs3Zu663huONg9Gi4/fZ8YnCyMDPrAM46K11Oe/DBqdPBtuZkYWbWAfTokS6nnTMH9t237UfXc7IwM+sgVl0VrrwSnngCzjmnbfftZGFm1oHst18qWZxxBjz5ZNvt18nCzKyDueIKGDIkja43Y0bFxVuFk4WZWQez1FKp/eKtt+CQQ9qmO5C62u+iAzj6aHj++byjMDOr2kbAvwfBpNtgwvThrP3gJTXdn0sWZmYd1KDBaQzvaW0wqrRLFgCX1DYjm5nVgoDVP4XevWu/L5cszMw6sLZIFOBkYWZmVXCyMDOzipwszMysIicLMzOryMnCzMwqcrIwM7OKnCzMzKwiRVt0KtIGJH0A/KvES32BD6qY1x+YVoPQKikVS1ttp5p1Ki3T1OvlXmvv5wRa57zU6pxUs1ytzktHPyeLup3O/L+yckQMqLhURHSKBzC62vll5jW0p7jbYjvVrFNpmaZe76jnpLXOS63OSZ7npaOfk1qel87+v9KZqqHuacb8csvmobViWZTtVLNOpWWaer2jnhNonXhqdU6qWa4znhf/r1QfS6vrNNVQLSWpISLq847D5vM5aX98Ttqntjgvnalk0VKj8w7AFuJz0v74nLRPNT8vLlmYmVlFLlmYmVlFThZmZlaRk4WZmVXkZFGBpJ0l/UrSXZK2yTseSyStIunXkm7PO5auTNLikq7P/kf2yTseS2rx/9Gpk4WkayX9V9I/i+ZvJ+kVSRMlndDUNiLi9xFxMHAAsGcNw+0yWum8TIqIUbWNtGtq5vnZBbg9+x/Zqc2D7UKac15q8f/RqZMFMAbYrnCGpO7AFcD2wJrASElrSlpH0h+KHssVrHpytp613Bha77xY6xtDlecHGAhMzhab24YxdkVjqP68tLq6Wmy0vYiIxyUNKZq9ETAxIiYBSBoLjIiInwI7Fm9DkoDzgPsj4tnaRtw1tMZ5sdppzvkBppASxvN0/h+fuWrmeXmxtfffFU/uSsz/JQTpw75SE8sfCXwD2E3SobUMrItr1nmRtKykq4H1JZ1Y6+Cs7Pn5HbCrpKtoX12DdBUlz0st/j86dcmiDJWYV/bOxIi4FLi0duFYprnn5T3AybvtlDw/EfExcGBbB2P/U+68tPr/R1csWUwBBhVMDwTeyikWm8/npX3z+Wmf2uy8dMVk8QwwTNJQST2BvYC7c47JfF7aO5+f9qnNzkunThaSbgaeAr4kaYqkURExBzgCeAB4Cbg1IibkGWdX4/PSvvn8tE95nxd3JGhmZhV16pKFmZm1DicLMzOryMnCzMwqcrIwM7OKnCzMzKwiJwszM6vIycJKkvQdSSFp9YJ5Q4q7Ry6xXsVlqtj3zpJObeE2HpNUnz1/SNLSLdleE/t5XVL/EvM/auZ2dl6U3kILj5WkMZJ2K7HMlpL+0NxtF6zfasev3PGy9s/JwsoZCfyFdEdoWzsOuLJ4pqRF7cvsBuAHLYqo9nYmdTHdXCWPVSvrCMfPaszJwhYiaQlgM2AUZZKFpAOURg/8YzbwymkFL3dXGjltgqQ/SeqTrXOwpGckjZd0h6TFSmz3i8BnETEtmx4j6SJJjwI/UxqZ7dpsO89JGpEt10fSWEkvSLoF6FOw2btJya/U+7hKUkMW6xkF81+XdIakZyX9o7GElfXm+ads37+kdEdujdu4MFv/YUkDsnmrZsdsnKQnJK0uaVPSwEEXSHo+W6bZxyrzjWy7r0oq1eX+6ZJ+UjD9T2XdXkvaV9Lfsxh+qTRWQtnjJ+kwSecXTB8g6bLs+e+z9zhB0iEl1l2gBCrpJ5JOL3eMsvm7Z/GOl/R4ueNuteFkYaXsDPwxIl4F3pf05TLLbQTsAwwHdm+s9gGGAVdExFrADGDXbP7vImLDiFiP1DVBqZG8NgOKxw35IvCNiDgG+D/gkYjYEPg66Qt2ceAwYFZErAucA2zQuHJETAd6SVq2xP7+LyLqgXWBr0lat+C1aRHxZeAqoPEL9jTgLxGxPulLdHCZY7M48Gy2/p+z9QBGA0dGxAbZNq+MiL9m2zo2IoZHxL9bcKyGAF8DvgVcLal3mfgWIGkN0kiQm0XEcNJARvtAk8fvdtJIeY32BG7Jnh+Uvcd64Kgyx76chY5RNv9UYNvsmHhUvjbWFbsot8pGApdkz8dm06UGfnow6woZSb8DNgd+D7wWEc9ny4wjfYEBrC3pbKAfsASpP5tiXwCmFs27LSIaR2HbBtip4Ndxb9IX9hZkXclHxAuSXijaxn+BFYH3iubvkf3yrcv2vSbQuO7vCt5D45fiFo3PI+JeSdNLvAeAecz/4rwR+F1WYtsUuE36X4GkV5n1F/VY3RoR84B/SZoErL7waiVtTUqwz2Sx9SEds0YLHb+ImCppkqSvAP8CvgQ8mb18lKTvZM8HkX5AFB/7hVQ4Rk8CYyTdyvxzY23EycIWkP0C3Ir0ZRVAdyAkHVdi8eKOxRqnPyuYN5f5VUJjgJ0jYrykA4AtS2zzE6Bv0byPC0MEdo2IV4riLhVPod7ZtgvXGUr65bphREyXNCZbrlHj+5jLgv8ri9KhWpBK8jOyX+6VjGHRjlW5c9JoDgvWKDS+XwHXR0S5gXIWOn6ZW4A9gJeBOyMiJG1JGjBsk4iYJekxFjyuTcVR9hhFxKGSNiaVmp6XNLzxx4rVnquhrNhuwG8iYuWIGBIRg4DXSKWGYt+UtEzWJrEz839VlrMk8LakHmRVHCW8BKzWxDYeAI5Ulh0krZ/Nf7xxm5LWJlUrkU0LWAF4vWhbS5ES0QeSlieNY1xJ4X62B8pdJdSNdCwB9iZVXX0IvCZp98a4JK2XLTOTdHwaLeqx2l1SN0mrAqsArxS9/jrw5Wz/XwaGZvMfJo0GuVz22jKSVm6Mk9LHD9Iv/J1Jpc/GklRfYHqWKFYHvlJivXeB5bI2oF5kQ+c2dYwkrRoRf4uIU4FpLDiOg9WYk4UVGwncWTTvDtIXXrG/kK6UeR64IyIaKmz7FOBvwIOkX6KlPE4aCrJcw/FZQA/ghayB9Kxs/lXAEln103HA3wvW2QB4OuvO+X8iYjzwHDABuJbKyQ7gDGALSc+SqsTeLLPcx8BaksaRSmpnZvP3AUZJGp/td0Q2fyxwrFLD+aos+rF6hdRGcj9waER8WrTOHcAykp4ntfO8ChARLwInA3/KjuGDpGouKHP8svWmk8Z7XjkiGo/5H4G6bDtnAU+XWG92dkz+Bvyh6D2WO0YXKF1s8M/svY8vc1ysBtxFuS2SrGqkPiKOqMG2fwHcExEPteL27o6Ih1tje+1Jax+rJvbRKY+fVc8lC2uPzgUWulS0Bf7Zib/oWvtYldKZj59VySULMzOryCULMzOryMnCzMwqcrIwM7OKnCzMzKwiJwszM6vIycLMzCr6f+s85MmOBQBxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x198b5298fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x198b4f96d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.semilogx(subsy=[0.01, 0.1, 1.0, 10.0])\n",
    "plt.yticks([0.78, 0.8, 0.82, 0.84, 0.86, 0.88])\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [0.892, 0.887, 0.856, 0.768], 'b')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [0.892, 0.892, 0.892, 0.891], 'r')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [0.887, 0.886, 0.886, 0.887], 'r')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [0.856, 0.856, 0.856, 0.862], 'r')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [0.768, 0.768, 0.768, 0.768], 'r')\n",
    "plt.xlabel('Alpha (red) and beta (blue) values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy with varying values of alpha and beta')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.semilogx(subsy=[0.01, 0.1, 1.0, 10.0])\n",
    "plt.yticks([42.5, 45, 47.5, 50, 52.5])\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [53.449, 47.331, 41.961, 41.162], 'b')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [53.449, 53.445, 53.414, 53.127], 'r')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [47.331, 47.33, 47.317, 47.194], 'r')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [41.961, 41.96, 41.957, 41.922], 'r')\n",
    "plt.plot([0.01, 0.1, 1.0, 10.0], [41.162, 41.162, 41.161, 41.156], 'r')\n",
    "plt.xlabel('Alpha (red) and beta (blue) values')\n",
    "plt.ylabel('Logarithmic perplexity')\n",
    "plt.title('Logarithmic perplexity on varying values of alpha and beta')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "id": "rfwVaSMnvVBP",
    "outputId": "ee4c7d77-11e4-4f72-f688-e63ee217a2f9"
   },
   "outputs": [],
   "source": [
    "# # Optional: Brown treebank too\n",
    "\n",
    "# brown_sentences = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "# brown_training = list(brown_sentences[:56000])\n",
    "# brown_dev = list(brown_sentences[56000:56340])\n",
    "# brown_test = list(brown_sentences[56340:])\n",
    "\n",
    "# brown_hmm = HMMLM()\n",
    "# brown_hmm.estimate_model(treebank_training)\n",
    "\n",
    "# print(brown_hmm.joint_parameter('DET', 'NOUN', 'book'))\n",
    "# sentence = [x for x, _ in treebank_dev[0]]\n",
    "# tag_sequence = [c for _, c in treebank_dev[0]]\n",
    "# print(brown_hmm.log_joint(sentence, tag_sequence))\n",
    "\n",
    "# brown_gold = make_tag_sents(brown_test)\n",
    "# sents_brown = make_word_sents(brown_test)\n",
    "\n",
    "# print(determine_viterbi_rec_accuracy(\n",
    "#     brown_hmm, brown_gold[:5], sents_brown[:5]))\n",
    "# # print(determine_viterbi_rec_accuracy(brown_hmm, brown_gold, sents_brown))\n",
    "# # print(determine_viterbi_rec_accuracy(brown_hmm, ptb_gold, sents_ptb))\n",
    "# # print(determine_viterbi_rec_accuracy(treebank_hmm, brown_gold, sents_brown))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Lab5-Colab.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
