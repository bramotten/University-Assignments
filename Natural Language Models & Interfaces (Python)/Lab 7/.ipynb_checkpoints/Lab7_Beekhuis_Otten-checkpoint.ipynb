{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lennart Beekhuis, 11344873\n",
    "# Bram Otten, 10992456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**\n",
    "\n",
    "* [PCFG lib](#lib)\n",
    "    * [Span](#span)\n",
    "* [CKY+](#cky+)\n",
    "    * [Item](#item)\n",
    "    * [Agenda](#agenda)\n",
    "    * [Inference rules](#inference-rules)\n",
    "    * [Deduction](#deduction)\n",
    "* [PCFG recap](#pcfg)\n",
    "* [Inside](#inside)\n",
    "    * [Semirings](#semirings)\n",
    "   \n",
    "   \n",
    "    \n",
    "**Table of Exercises**\n",
    "\n",
    "* Theory (9 points)\n",
    "    * [Exercise 7-1](#ex7-1)\n",
    "    * [Exercise 7-2](#ex7-2)\n",
    "    * [Exercise 7-3](#ex7-3)\n",
    "    * [Exercise 7-4](#ex7-4)\n",
    "    * [Exercise 7-5](#ex7-5)    \n",
    "* Practicals (26 points)    \n",
    "    * [Exercise 7-6](#ex7-6)\n",
    "    * [Exercise 7-7](#ex7-7)\n",
    "    * [Exercise 7-8](#ex7-8)\n",
    "* Bonus (see below for information about points)    \n",
    "    * Theory: [Exercise 7-9](#ex7-9)\n",
    "    * Practical: [Exercise 7-10](#ex7-10)    \n",
    "\n",
    "\n",
    "**General notes**\n",
    "\n",
    "* In this notebook you are expected to use $\\LaTeX$\n",
    "* Use python3.\n",
    "* Use NLTK to read annotated data.\n",
    "* **Document your code**: TAs are more likely to understand the steps if you document them. If you don't, it's also difficult to give you partial points for exercises that are not completely correct.\n",
    "* This document contains 2 optional exercises worth bonus points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"lib\">  PCFG lib\n",
    "\n",
    "We are going to use the basic objects defined in the last lab\n",
    "\n",
    "* Symbol, Terminal, and Nonterminal\n",
    "* Rule, and CFG\n",
    "\n",
    "Check the file `pcfglib.py` where you will find these definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcfglib import Symbol, Terminal, Nonterminal, Rule, CFG\n",
    "# from Lab6 import Symbol, Terminal, Nonterminal, Rule, CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"span\"> Span\n",
    "\n",
    "\n",
    "For convenience, we will define one more type of Symbol, this will be a Span. A Span is just a Nonterminal decorated with two integers which represent a half-open interval $(i, j]$, that is:\n",
    "\n",
    "* start (exclusive) of phrase\n",
    "* end (inclusive) of phrase\n",
    "\n",
    "It is very easy to define such Span class by inheriting from Nonterminal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span(Nonterminal):\n",
    "\n",
    "    def __init__(self, nonterminal: Nonterminal, start: int, end: int):\n",
    "        \"\"\"\n",
    "        :param nonterminal: a Nonterminal category\n",
    "        :param start: start position of the phrase (exclusive)\n",
    "        :param end: end position of the phrase (inclusive)\n",
    "        \"\"\"\n",
    "        if not isinstance(nonterminal, Nonterminal):\n",
    "            raise ValueError('Only a Nonterminal can make a span')\n",
    "        super(Span, self).__init__('%s:%d-%d' %\n",
    "                                   (nonterminal.category, start, end))\n",
    "        self._base_nonterminal = nonterminal\n",
    "        self._span = (start, end)\n",
    "\n",
    "    @property\n",
    "    def base_nonterminal(self) -> Nonterminal:\n",
    "        \"\"\"Returns the base nonterminal: the Nonterminal without span information\"\"\"\n",
    "        return self._base_nonterminal\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        \"\"\"Begin of the span (open)\"\"\"\n",
    "        return self._span[0]\n",
    "\n",
    "    @property\n",
    "    def end(self):\n",
    "        \"\"\"End of the span (closed)\"\"\"\n",
    "        return self._span[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function definition below constructs our running example PCFG. Note that it returns both the CFG object and the cpds.\n",
    "\n",
    "As in the previous lab a collection of cpds is stored in a dictionary such that ```cpds[lhs]``` is a dictionary mapping from rules that rewrite that LHS symbol to their probability values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_toy_pcfg():\n",
    "    # Some symbols\n",
    "    S = Nonterminal('S')\n",
    "\n",
    "    NP = Nonterminal('NP')\n",
    "    VP = Nonterminal('VP')\n",
    "    PP = Nonterminal('PP')\n",
    "\n",
    "    NN = Nonterminal('NN')\n",
    "    Vt = Nonterminal('Vt')\n",
    "    Vi = Nonterminal('Vi')\n",
    "    DT = Nonterminal('DT')\n",
    "    IN = Nonterminal('IN')\n",
    "    CC = Nonterminal('CC')\n",
    "\n",
    "    # Grammar\n",
    "    G = CFG(S)\n",
    "    cpds = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    # Phrasal rules\n",
    "    G.add(Rule(S, [NP, VP]))\n",
    "    cpds[S][Rule(S, [NP, VP])] = 1.0\n",
    "\n",
    "    G.add(Rule(NP, [DT, NN]))\n",
    "    G.add(Rule(NP, [NN]))\n",
    "    G.add(Rule(NP, [NP, PP]))\n",
    "    G.add(Rule(NP, [NP, CC, NP]))\n",
    "    cpds[NP][Rule(NP, [DT, NN])] = 0.4\n",
    "    cpds[NP][Rule(NP, [NN])] = 0.1\n",
    "    cpds[NP][Rule(NP, [NP, PP])] = 0.3\n",
    "    cpds[NP][Rule(NP, [NP, CC, NP])] = 0.2\n",
    "\n",
    "    G.add(Rule(VP, [Vt, NP]))\n",
    "    G.add(Rule(VP, [VP, PP]))\n",
    "    G.add(Rule(VP, [Vi]))\n",
    "    G.add(Rule(VP, [VP, CC, VP]))\n",
    "    cpds[VP][Rule(VP, [Vt, NP])] = 0.3\n",
    "    cpds[VP][Rule(VP, [VP, PP])] = 0.4\n",
    "    cpds[VP][Rule(VP, [Vi])] = 0.2\n",
    "    cpds[VP][Rule(VP, [VP, CC, VP])] = 0.1\n",
    "\n",
    "    G.add(Rule(PP, [IN, NP]))\n",
    "    cpds[PP][Rule(PP, [IN, NP])] = 1.\n",
    "\n",
    "    # Preterminal rules\n",
    "    G.add(Rule(NN, [Terminal('dog')]))\n",
    "    G.add(Rule(NN, [Terminal('cat')]))\n",
    "    G.add(Rule(NN, [Terminal('man')]))\n",
    "    G.add(Rule(NN, [Terminal('telescope')]))\n",
    "\n",
    "    cpds[NN][Rule(NN, [Terminal('dog')])] = 0.3\n",
    "    cpds[NN][Rule(NN, [Terminal('cat')])] = 0.2\n",
    "    cpds[NN][Rule(NN, [Terminal('man')])] = 0.4\n",
    "    cpds[NN][Rule(NN, [Terminal('telescope')])] = 0.1\n",
    "\n",
    "    G.add(Rule(DT, [Terminal('the')]))\n",
    "    G.add(Rule(DT, [Terminal('a')]))\n",
    "    cpds[DT][Rule(DT, [Terminal('the')])] = 0.6\n",
    "    cpds[DT][Rule(DT, [Terminal('a')])] = 0.4\n",
    "\n",
    "    G.add(Rule(CC, [Terminal('and')]))\n",
    "    G.add(Rule(CC, [Terminal(',')]))\n",
    "    cpds[CC][Rule(CC, [Terminal('and')])] = 0.8\n",
    "    cpds[CC][Rule(CC, [Terminal(',')])] = 0.2\n",
    "\n",
    "    G.add(Rule(IN, [Terminal('with')]))\n",
    "    G.add(Rule(IN, [Terminal('through')]))\n",
    "    G.add(Rule(IN, [Terminal('within')]))\n",
    "    cpds[IN][Rule(IN, [Terminal('with')])] = 0.5\n",
    "    cpds[IN][Rule(IN, [Terminal('through')])] = 0.3\n",
    "    cpds[IN][Rule(IN, [Terminal('within')])] = 0.2\n",
    "\n",
    "    G.add(Rule(Vt, [Terminal('saw')]))\n",
    "    G.add(Rule(Vt, [Terminal('barked')]))\n",
    "    G.add(Rule(Vt, [Terminal('meowed')]))\n",
    "    G.add(Rule(Vt, [Terminal('moved')]))\n",
    "    cpds[Vt][Rule(Vt, [Terminal('saw')])] = 0.4\n",
    "    cpds[Vt][Rule(Vt, [Terminal('barked')])] = 0.3\n",
    "    cpds[Vt][Rule(Vt, [Terminal('meowed')])] = 0.2\n",
    "    cpds[Vt][Rule(Vt, [Terminal('moved')])] = 0.1\n",
    "\n",
    "    G.add(Rule(Vi, [Terminal('barked')]))\n",
    "    G.add(Rule(Vi, [Terminal('ran')]))\n",
    "    G.add(Rule(Vi, [Terminal('meowed')]))\n",
    "    cpds[Vi][Rule(Vi, [Terminal('barked')])] = 0.2\n",
    "    cpds[Vi][Rule(Vi, [Terminal('ran')])] = 0.7\n",
    "    cpds[Vi][Rule(Vi, [Terminal('meowed')])] = 0.1\n",
    "\n",
    "    return G, cpds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S] -> [NP] [VP]\n",
      "[NP] -> [DT] [NN]\n",
      "[NP] -> [NN]\n",
      "[NP] -> [NP] [PP]\n",
      "[NP] -> [NP] [CC] [NP]\n",
      "[PP] -> [IN] [NP]\n",
      "[VP] -> [Vt] [NP]\n",
      "[VP] -> [VP] [PP]\n",
      "[VP] -> [Vi]\n",
      "[VP] -> [VP] [CC] [VP]\n",
      "[CC] -> 'and'\n",
      "[CC] -> ','\n",
      "[DT] -> 'the'\n",
      "[DT] -> 'a'\n",
      "[IN] -> 'with'\n",
      "[IN] -> 'through'\n",
      "[IN] -> 'within'\n",
      "[NN] -> 'dog'\n",
      "[NN] -> 'cat'\n",
      "[NN] -> 'man'\n",
      "[NN] -> 'telescope'\n",
      "[Vi] -> 'barked'\n",
      "[Vi] -> 'ran'\n",
      "[Vi] -> 'meowed'\n",
      "[Vt] -> 'saw'\n",
      "[Vt] -> 'barked'\n",
      "[Vt] -> 'meowed'\n",
      "[Vt] -> 'moved'\n"
     ]
    }
   ],
   "source": [
    "G, cpds = get_toy_pcfg()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as our cpds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 [S] -> [NP] [VP]\n",
      "0.4 [NP] -> [DT] [NN]\n",
      "0.1 [NP] -> [NN]\n",
      "0.3 [NP] -> [NP] [PP]\n",
      "0.2 [NP] -> [NP] [CC] [NP]\n",
      "0.3 [VP] -> [Vt] [NP]\n",
      "0.4 [VP] -> [VP] [PP]\n",
      "0.2 [VP] -> [Vi]\n",
      "0.1 [VP] -> [VP] [CC] [VP]\n",
      "1.0 [PP] -> [IN] [NP]\n",
      "0.3 [NN] -> 'dog'\n",
      "0.2 [NN] -> 'cat'\n",
      "0.4 [NN] -> 'man'\n",
      "0.1 [NN] -> 'telescope'\n",
      "0.6 [DT] -> 'the'\n",
      "0.4 [DT] -> 'a'\n",
      "0.8 [CC] -> 'and'\n",
      "0.2 [CC] -> ','\n",
      "0.5 [IN] -> 'with'\n",
      "0.3 [IN] -> 'through'\n",
      "0.2 [IN] -> 'within'\n",
      "0.4 [Vt] -> 'saw'\n",
      "0.3 [Vt] -> 'barked'\n",
      "0.2 [Vt] -> 'meowed'\n",
      "0.1 [Vt] -> 'moved'\n",
      "0.2 [Vi] -> 'barked'\n",
      "0.7 [Vi] -> 'ran'\n",
      "0.1 [Vi] -> 'meowed'\n"
     ]
    }
   ],
   "source": [
    "for lhs, cpd in cpds.items():\n",
    "    for rule, prob in cpd.items():\n",
    "        print(prob, rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"cky+\"> CKY+ \n",
    "\n",
    "\n",
    "In this section we will implement a generalised CKY algorithm which can deal with an arbitrary epsilon-free CFG.\n",
    "\n",
    "We will implement the parsing strategy **for you** to guarantee that it is correct. The focus of this lab is on the **inside recursion**. An extra will involve implementing a different parsing strategy, for that some of the data structures we will develop here are indeed very useful, thus take this as a learning opportunity and try to reuse some code if you decide to implement the extra.\n",
    "\n",
    "There will be nonetheless questions throught this lab, so stay tuned.\n",
    "\n",
    "\n",
    "Again we will use a deductive system to describe the parsing strategy:\n",
    "\n",
    "\\begin{align}\n",
    "\\text{Item} &\\qquad [i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, \\beta_\\square, j] \\\\\n",
    "\\text{Goal} &\\qquad [1, S \\rightarrow \\beta_\\blacksquare \\, \\bullet, n]  \\\\\n",
    "\\text{Axioms} &\\qquad [i, X \\rightarrow \\bullet \\alpha_\\square, i] &~\\text{ for all } X \\rightarrow \\alpha \\in \\mathcal R \\\\\n",
    "\\text{Scan} &\\qquad \\frac{[i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, x_{j+1}  \\, \\beta_\\square, j]}{[i, X \\rightarrow \\alpha_\\blacksquare \\, x_{j+1} \\bullet \\, \\beta_\\square, j + 1]} \\\\\n",
    "\\text{Complete} &\\qquad \\frac{[i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, Y \\, \\beta_\\square ,k] [k, Y \\rightarrow \\gamma_\\blacksquare \\, \\bullet , j]}{[i,  X \\rightarrow \\alpha_\\blacksquare \\, Y_{k,j} \\, \\bullet \\, \\beta_\\square , j]}\n",
    "\\end{align}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-1\" style=\"color:red\">**Exercise 7-1**</a> **[1 point]** Explain the meaning of an item (make sure to discuss all elements in it).\n",
    "\n",
    "The $i$ and $j$ are indices that work on the sentence that is being parsed. These indices don't correspond to words, but to spaces before or after words. We start 'picking up' content at index $i$, and stop at index $j$ (inclusive).\n",
    "\n",
    "$X$ is the left hand side of a rule from $\\mathcal{R}$, $\\alpha_\\blacksquare \\, \\bullet \\, \\beta_\\square$ the right hand side. The $\\alpha_\\blacksquare$ part of rewriting $X$ is done (as in true, it fits with these indices of the sentence), the $\\beta_\\square$ part must still be filled in and is thus only 'predicted.'\n",
    "\n",
    "In general, the $\\bullet$ represents progress thougha rule, the $\\blacksquare$ indicates 'done,' and the $\\square$ indicates 'todo.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-2\" style=\"color:red\">**Exercise 7-2**</a> **[1 point]** Explain the goal of the program\n",
    "\n",
    "To have converted a full string (if starting at index 1 and ending at $n$) to terminals from $\\mathcal{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-3\" style=\"color:red\">**Exercise 7-3**</a> **[1 point]** Explain the axioms of the program\n",
    "\n",
    "Makes it possible to 'initiate' a rule from $\\mathcal{R}$: replace a LHS with a RHS. The indices ($i$) are the same here as the right bound can't be known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-4\" style=\"color:red\">**Exercise 7-4**</a> **[1 point]** Explain SCAN (make sure to discuss all elements of the rule)\n",
    "\n",
    "If there is an item which can be parsed at the end of the currently parsed sentence (upper part of rule), then parse it and update the sentence (bottom part of rule)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-5\" style=\"color:red\">**Exercise 7-5**</a> **[1 point]** Explain the COMPLETE rule including all of its elements including the side condition.\n",
    "\n",
    "If there is an item at the end of the currently parsed sentence (top left), which has already been completely induced (top right), then parse it to the sentence and update (bottom)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual **deduction** is nothing but an exhaustive enumeration of valid items.\n",
    "* we start from axioms\n",
    "* and proceed by either scanning or completing previously derived items\n",
    "* each such operation creates additional items\n",
    "* if these items were not yet discovered, they make it to what we call an **agenda**\n",
    "* the agenda is much like a queue of items yet to be processed\n",
    "* processing an item means simply giving it the chance to participate in scan and complete\n",
    "* we should be careful to never process an item twice under the same premises \n",
    "* items that are yet to be processed are called **active items**\n",
    "* items already processed are called **passive items**\n",
    "* at the end there should be no active item and many passive items\n",
    "* parsing is possible if we derive/prove/reach the goal item\n",
    "* the complete items in the passive set can be used to derive a **parse forest**\n",
    "* a parse forest is much like a CFG but its rules have symbols which are decorated with spans indicating how they parse the input sentence\n",
    "* we can use parse forests to answer questions such as: what trees can parse the sentence? And when we introduce PCFGs, we will be able to answer quetions such as: what's the best tree that parses the sentence? what's the total probability value of the sentence (once we marginalise all possible parse trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn to implementation, which will require a few classes and data structures, but we will discuss them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"item\"> Item\n",
    "\n",
    "We have to start by turning items into code!\n",
    "\n",
    "We are using dotted rules to represent items in CKY+. A dotted rule is basically a container for \n",
    "* a context-free production\n",
    "* a list of positions already covered in the input sentence\n",
    "    * together this represents the start and end position as well as the black squares in the item\n",
    "    \n",
    "    \n",
    "This is an item formally\n",
    "\n",
    "\\begin{align}\n",
    "\\qquad [i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, \\beta_\\square, j]\n",
    "\\end{align}\n",
    "    \n",
    "and this is how we realise it in our implementation\n",
    "\n",
    "        [LHS -> RHS, [i...j]]\n",
    "\n",
    "the first element of the pair is the rule `LHS -> RHS` and the second is a list of positions where the dot has been.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "    \"\"\"\n",
    "    A dotted rule used in CKY\n",
    "\n",
    "    We store a rule and a list of positions (which we call `dots` because they indicate \n",
    "     positions where the dots have been)\n",
    "\n",
    "    We make an Item a hashable object so that we can use it in dictionaries.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rule: Rule, dots: list):\n",
    "        if len(dots) == 0:\n",
    "            raise ValueError('I do not accept an empty list of dots')\n",
    "        self._rule = rule\n",
    "        self._dots = tuple(dots)\n",
    "\n",
    "    def __eq__(self, other: 'Item'):\n",
    "        \"\"\"Two items are identical if they contain the same rule and cover the same positions\"\"\"\n",
    "        return self._rule == other._rule and self._dots == other._dots\n",
    "\n",
    "    def __hash__(self):\n",
    "        \"\"\"We let python hash the two objects that represent an Item\"\"\"\n",
    "        return hash((self._rule, self._dots))\n",
    "\n",
    "    def __str__(self):\n",
    "        return '[{0}, {1}]'.format(self._rule, self._dots)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)\n",
    "\n",
    "    @property\n",
    "    def lhs(self):\n",
    "        return self._rule.lhs\n",
    "\n",
    "    @property\n",
    "    def rule(self):\n",
    "        return self._rule\n",
    "\n",
    "    @property\n",
    "    def dot(self):\n",
    "        return self._dots[-1]\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        return self._dots[0]\n",
    "\n",
    "    @property\n",
    "    def next(self):\n",
    "        \"\"\"return the symbol to the right of the dot (or None, if the item is complete)\"\"\"\n",
    "        if self.is_complete():\n",
    "            return None\n",
    "        return self._rule.rhs[len(self._dots) - 1]\n",
    "\n",
    "    def state(self, i):\n",
    "        return self._dots[i]\n",
    "\n",
    "    def advance(self, dot):\n",
    "        \"\"\"return a new item with an extended sequence of dots\"\"\"\n",
    "        return Item(self._rule, self._dots + (dot,))\n",
    "\n",
    "    def is_complete(self):\n",
    "        \"\"\"complete items are those whose dot reached the end of the RHS sequence\"\"\"\n",
    "        return len(self._rule.rhs) + 1 == len(self._dots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play a bit with item objects to see how they work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rule(Nonterminal('S'), [Nonterminal('X')])\n",
    "i1 = Item(r, [0])\n",
    "i2 = i1.advance(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[S] -> [X], (0,)]\n",
      "[[S] -> [X], (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(i1)\n",
    "print(i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1 != i2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1.is_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2.is_complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[X]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"agenda\"> Agenda\n",
    "\n",
    "Next we need an agenda of items. In CKY+ we have to track quite a bit of information, so we will design a more complex agenda. Because there will be a lot of functionality, we will use a class. \n",
    "\n",
    "In an agenda, some items are active, others are passive.\n",
    "\n",
    "Functionally, the active agenda is nothing but a stack or queue, whereas the passive agenda is simply a set (all items that have already been processed). However, to make our inferences run faster, we can further organise the passive items for easy/quick access within inference rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, defaultdict\n",
    "\n",
    "\n",
    "class Agenda:\n",
    "    \"\"\"\n",
    "    An Agenda for CKY+.\n",
    "\n",
    "    The agenda will organise a queue of active items as well as a set of passive items.\n",
    "\n",
    "    This agenda is such that it does not push an item twice into the queue \n",
    "        that is equivalent to saying that the agenda is capable of maintaining a set of already discovered items.\n",
    "\n",
    "    This agenda will also organise the passive items for quick access in the COMPLETE rule. \n",
    "        This means we will store complete and incomplete items separately and hash them by some useful criterion.\n",
    "        A complete item essentially contributes to further advancing incomplete items. \n",
    "        Incomplete items need to be further completed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # we are organising active items in a stack (last in first out)\n",
    "        self._active = deque([])\n",
    "        # an item should never queue twice, thus we will manage a set of items which we have already seen\n",
    "        self._discovered = set()\n",
    "\n",
    "        # Passive items may be complete\n",
    "        #   in which case they help us complete other items\n",
    "        #  and they may be incomplete\n",
    "        #   in which case we will be trying to complete them\n",
    "        # In order to make COMPLETE inferences easier, we will separate passive items into these two groups\n",
    "        #  and we will also organise each group conveniently.\n",
    "\n",
    "        # We organise incomplete items by the symbols they wait for at a certain position\n",
    "        #  that is, if the key is a pair (Y, i)\n",
    "        #  the value is a set of items of the form\n",
    "        #    [X -> alpha * Y beta, [...i]]\n",
    "        #  in other words \"items waiting for a Y to project a span from i\"\n",
    "        self._incomplete = defaultdict(set)\n",
    "\n",
    "        # We organise complete items by their LHS symbol spanning from a certain position\n",
    "        #  if the key is a pair (X, i)\n",
    "        #  then the value is a set of items of the form\n",
    "        #   [X -> gamma *, [i ... j]]\n",
    "        self._complete = defaultdict(set)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return the number of active items\"\"\"\n",
    "        return len(self._active)\n",
    "\n",
    "    def push(self, item: Item):\n",
    "        \"\"\"push an item into the queue of active items\"\"\"\n",
    "        if item not in self._discovered:  # if an item has been seen before, we simply ignore it\n",
    "            self._active.append(item)\n",
    "            self._discovered.add(item)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"pop an active item\"\"\"\n",
    "        if len(self._active) == 0:\n",
    "            raise ValueError('I have no items left')\n",
    "        return self._active.pop()\n",
    "\n",
    "    def make_passive(self, item: Item):\n",
    "        if item.is_complete():  # complete items offer a way to rewrite a certain LHS from a certain position\n",
    "            self._complete[(item.lhs, item.start)].add(item)\n",
    "        else:  # incomplete items are waiting for the completion of the symbol to the right of the dot\n",
    "            self._incomplete[(item.next, item.dot)].add(item)\n",
    "\n",
    "    def waiting(self, symbol: Symbol, dot: int):\n",
    "        return self._incomplete.get((symbol, dot), set())\n",
    "\n",
    "    def complete(self, lhs: Nonterminal, start: int):\n",
    "        return self._complete.get((lhs, start), set())\n",
    "\n",
    "    def itercomplete(self):\n",
    "        \"\"\"an iterator over complete items in arbitrary order\"\"\"\n",
    "        for items in self._complete.values():\n",
    "            for item in items:\n",
    "                yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Agenda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S] -> [S] [X]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = Rule(Nonterminal('S'), [Nonterminal('S'), Nonterminal('X')])\n",
    "r1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can push items into the agenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.push(Item(r1, [0]))  # S -> S X, [0]  (earley axiom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the agenda will make sure there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.push(Item(r1, [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[S] -> [S] [X], (0,)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i1 = Item(r1, [0])\n",
    "i1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.make_passive(i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.push(Item(Rule(Nonterminal('S'), [Nonterminal('X')]), [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.make_passive(Item(Rule(Nonterminal('S'), [Nonterminal('X')]), [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.push(Item(Rule(Nonterminal('S'), [Nonterminal('X')]), [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.make_passive(Item(Rule(Nonterminal('S'), [Nonterminal('X')]), [0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[S] -> [X], (0, 1)]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(A.itercomplete())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"inference-rules\"> Inference rules\n",
    "\n",
    "### Basic axioms\n",
    "\n",
    "For every rule X -> alpha, and every input position (i) between 0 and n-1, we have an item of the kind:\n",
    "\n",
    "\\begin{equation}\n",
    "[i, X \\rightarrow \\bullet \\alpha_\\square, i]\n",
    "\\end{equation}\n",
    "\n",
    "In our implementation an axiom looks like this\n",
    "\n",
    "         [X -> alpha, [i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axioms(cfg: CFG, sentence: list):\n",
    "    \"\"\"\n",
    "    :params cfg: a context-free grammar (an instance of WCFG)\n",
    "    :params sentence: the input sentence (as a list or tuple)\n",
    "    :returns: a list of items\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for rule in cfg:\n",
    "        for i, x in enumerate(sentence):\n",
    "            # We will implement a tiny optimisation here\n",
    "\n",
    "            # For rules that start with terminals we can use \"look ahead\"\n",
    "            if isinstance(rule.rhs[0], Terminal):\n",
    "                # this is a mechanism by which we avoid constructing items which we know cannot be scanned\n",
    "                #  that's the terminal that starts the rule does not occur in the sentence we are parsing\n",
    "                if rule.rhs[0] == x:\n",
    "                    items.append(Item(rule, [i]))\n",
    "            else:\n",
    "                items.append(Item(rule, [i]))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look what type of axioms we get, note that CKY+ is very greedy. Earley parsing is an alternative strategy that's far more conservative than CKY+, for example, Earley avoids instantiating items that are not yet required and instead uses a simpler axiom (you will seee it later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[DT] -> 'the', (0,)],\n",
       " [[DT] -> 'the', (3,)],\n",
       " [[NP] -> [NP] [PP], (0,)],\n",
       " [[NP] -> [NP] [PP], (1,)],\n",
       " [[NP] -> [NP] [PP], (2,)],\n",
       " [[NP] -> [NP] [PP], (3,)],\n",
       " [[NP] -> [NP] [PP], (4,)],\n",
       " [[NP] -> [NP] [PP], (5,)],\n",
       " [[NP] -> [NP] [PP], (6,)],\n",
       " [[NP] -> [NP] [PP], (7,)],\n",
       " [[VP] -> [Vi], (0,)],\n",
       " [[VP] -> [Vi], (1,)],\n",
       " [[VP] -> [Vi], (2,)],\n",
       " [[VP] -> [Vi], (3,)],\n",
       " [[VP] -> [Vi], (4,)],\n",
       " [[VP] -> [Vi], (5,)],\n",
       " [[VP] -> [Vi], (6,)],\n",
       " [[VP] -> [Vi], (7,)],\n",
       " [[VP] -> [Vt] [NP], (0,)],\n",
       " [[VP] -> [Vt] [NP], (1,)],\n",
       " [[VP] -> [Vt] [NP], (2,)],\n",
       " [[VP] -> [Vt] [NP], (3,)],\n",
       " [[VP] -> [Vt] [NP], (4,)],\n",
       " [[VP] -> [Vt] [NP], (5,)],\n",
       " [[VP] -> [Vt] [NP], (6,)],\n",
       " [[VP] -> [Vt] [NP], (7,)],\n",
       " [[NN] -> 'dog', (4,)],\n",
       " [[NP] -> [NP] [CC] [NP], (0,)],\n",
       " [[NP] -> [NP] [CC] [NP], (1,)],\n",
       " [[NP] -> [NP] [CC] [NP], (2,)],\n",
       " [[NP] -> [NP] [CC] [NP], (3,)],\n",
       " [[NP] -> [NP] [CC] [NP], (4,)],\n",
       " [[NP] -> [NP] [CC] [NP], (5,)],\n",
       " [[NP] -> [NP] [CC] [NP], (6,)],\n",
       " [[NP] -> [NP] [CC] [NP], (7,)],\n",
       " [[Vt] -> 'saw', (2,)],\n",
       " [[S] -> [NP] [VP], (0,)],\n",
       " [[S] -> [NP] [VP], (1,)],\n",
       " [[S] -> [NP] [VP], (2,)],\n",
       " [[S] -> [NP] [VP], (3,)],\n",
       " [[S] -> [NP] [VP], (4,)],\n",
       " [[S] -> [NP] [VP], (5,)],\n",
       " [[S] -> [NP] [VP], (6,)],\n",
       " [[S] -> [NP] [VP], (7,)],\n",
       " [[NP] -> [NN], (0,)],\n",
       " [[NP] -> [NN], (1,)],\n",
       " [[NP] -> [NN], (2,)],\n",
       " [[NP] -> [NN], (3,)],\n",
       " [[NP] -> [NN], (4,)],\n",
       " [[NP] -> [NN], (5,)],\n",
       " [[NP] -> [NN], (6,)],\n",
       " [[NP] -> [NN], (7,)],\n",
       " [[NN] -> 'man', (1,)],\n",
       " [[PP] -> [IN] [NP], (0,)],\n",
       " [[PP] -> [IN] [NP], (1,)],\n",
       " [[PP] -> [IN] [NP], (2,)],\n",
       " [[PP] -> [IN] [NP], (3,)],\n",
       " [[PP] -> [IN] [NP], (4,)],\n",
       " [[PP] -> [IN] [NP], (5,)],\n",
       " [[PP] -> [IN] [NP], (6,)],\n",
       " [[PP] -> [IN] [NP], (7,)],\n",
       " [[NP] -> [DT] [NN], (0,)],\n",
       " [[NP] -> [DT] [NN], (1,)],\n",
       " [[NP] -> [DT] [NN], (2,)],\n",
       " [[NP] -> [DT] [NN], (3,)],\n",
       " [[NP] -> [DT] [NN], (4,)],\n",
       " [[NP] -> [DT] [NN], (5,)],\n",
       " [[NP] -> [DT] [NN], (6,)],\n",
       " [[NP] -> [DT] [NN], (7,)],\n",
       " [[IN] -> 'with', (5,)],\n",
       " [[VP] -> [VP] [CC] [VP], (0,)],\n",
       " [[VP] -> [VP] [CC] [VP], (1,)],\n",
       " [[VP] -> [VP] [CC] [VP], (2,)],\n",
       " [[VP] -> [VP] [CC] [VP], (3,)],\n",
       " [[VP] -> [VP] [CC] [VP], (4,)],\n",
       " [[VP] -> [VP] [CC] [VP], (5,)],\n",
       " [[VP] -> [VP] [CC] [VP], (6,)],\n",
       " [[VP] -> [VP] [CC] [VP], (7,)],\n",
       " [[NN] -> 'telescope', (7,)],\n",
       " [[VP] -> [VP] [PP], (0,)],\n",
       " [[VP] -> [VP] [PP], (1,)],\n",
       " [[VP] -> [VP] [PP], (2,)],\n",
       " [[VP] -> [VP] [PP], (3,)],\n",
       " [[VP] -> [VP] [PP], (4,)],\n",
       " [[VP] -> [VP] [PP], (5,)],\n",
       " [[VP] -> [VP] [PP], (6,)],\n",
       " [[VP] -> [VP] [PP], (7,)],\n",
       " [[DT] -> 'a', (6,)]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = [Terminal(w)\n",
    "            for w in 'the man saw the dog with a telescope'.split()]\n",
    "axioms(G, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan\n",
    "\n",
    "If the dot is placed at a position just before a *terminal*,  we can **scan** it provided that the terminal matches the corresponding input position.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{[i, A \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, x_{j+1}  \\, \\beta_\\square, j]}{[i, A \\rightarrow \\alpha_\\blacksquare \\, x_{j+1} \\bullet \\, \\beta_\\square, j + 1]}\n",
    "\\end{equation}\n",
    "\n",
    "In our implementation with dot lists it looks like this\n",
    "\n",
    "               [X -> alpha * x beta, [i ... j]] \n",
    "         --------------------------------------------\n",
    "          [X -> alpha x * beta, [i ... j] + [j + 1]]\n",
    "          \n",
    "\n",
    "note that the `*` is simply indicating where the last dot would be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan(item: Item, sentence):\n",
    "    if isinstance(item.next, Terminal):\n",
    "        if item.dot < len(sentence) and sentence[item.dot] == item.next:\n",
    "            return item.advance(item.dot + 1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[DT] -> 'the', (0, 1)],\n",
       " [[DT] -> 'the', (3, 4)],\n",
       " [[NN] -> 'dog', (4, 5)],\n",
       " [[Vt] -> 'saw', (2, 3)],\n",
       " [[NN] -> 'man', (1, 2)],\n",
       " [[IN] -> 'with', (5, 6)],\n",
       " [[NN] -> 'telescope', (7, 8)],\n",
       " [[DT] -> 'a', (6, 7)]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanned = []\n",
    "for item in axioms(G, sentence):\n",
    "    new = scan(item, sentence)\n",
    "    if new is not None:\n",
    "        scanned.append(new)\n",
    "scanned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete\n",
    "\n",
    "Here we let an active item interact with passive items:\n",
    "\n",
    "* either an active item is complete, then we try to advance incomplete passive items\n",
    "\n",
    "* or an active item is incomplete, in which case we try to advance the item itself by looking back to complete passive items\n",
    "\n",
    "Both cases are covered by the inference rule\n",
    "\n",
    "\\begin{align}\n",
    "\\qquad \\frac{[i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, Y \\, \\beta_\\square ,k] [k, Y \\rightarrow \\gamma_\\blacksquare \\, \\bullet , j]}{[i,  X \\rightarrow \\alpha_\\blacksquare \\, Y_{k,j} \\, \\bullet \\, \\beta_\\square , j]}\n",
    "\\end{align}\n",
    "\n",
    "In our implementation with dot lists it looks like this\n",
    "\n",
    "         [X -> alpha * Y beta, [i ... k]] [Y -> gamma *, [k ... j]]\n",
    "         ----------------------------------------------------------\n",
    "                 [X -> alpha Y * beta, [i ... k] + [j]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(item: Item, agenda: Agenda):\n",
    "    items = []\n",
    "    # This has two cases\n",
    "    # either the input item corresponds to the second antecedent in the COMPLETE inference rule\n",
    "    #  in which case the item is complete (the dot stands at the end)\n",
    "    # or the input item corresponds to the first antecedent in the COMPLETE inference rule\n",
    "    #  in which case the item is itself incomplete\n",
    "\n",
    "    # When it is *complete* we use it to advance incomplete ones.\n",
    "    # When it is *incomplete* we check if we know a complete item that can advance it.\n",
    "\n",
    "    # First we deal with the complete case\n",
    "    if item.is_complete():  # If the item is complete, it can be used to advance incomplete items\n",
    "        # We then look for incomplete items that are waiting for\n",
    "        #  the LHS nonterminal of our complete item\n",
    "        #  in particular, if it matches the start position of our complete item\n",
    "        for incomplete in agenda.waiting(item.lhs, item.start):\n",
    "            items.append(incomplete.advance(item.dot))\n",
    "    else:  # Then we deal with the incomplete case\n",
    "        # look for completions of item.next spanning from item.dot\n",
    "        ends = set()\n",
    "        for complete in agenda.complete(item.next, item.dot):\n",
    "            ends.add(complete.dot)\n",
    "        # advance the dot of the input item for each position that completes a span\n",
    "        for end in ends:\n",
    "            items.append(item.advance(end))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest from complete items\n",
    "\n",
    "Each **complete** item in the (passive) agenda can be mapped to a new CFG rule (with nonterminal symbols annotated with spans).\n",
    "For example, an item such as\n",
    "\n",
    "        [X -> A x B *, [0,1,2,3]]\n",
    "        \n",
    "results in the rule\n",
    "\n",
    "        X:0-3 -> A:0-1 x B:2-3\n",
    "        \n",
    "observe how only nonterminal nodes get annotated: this helps us keep terminals and nonterminals clearly separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_span(sym: Symbol, start: int, end: int):\n",
    "    \"\"\"\n",
    "    Helper function that returns a Span for a certain symbol.\n",
    "\n",
    "    This function will only make spans out of nonterminals, terminals are return as is.\n",
    "    :param sym: Terminal or Nonterminal symbol\n",
    "    :param start: open begin\n",
    "    :param end: closed end\n",
    "    :returns: Span(sym, start, end) or sym (if Terminal)\n",
    "    \"\"\"\n",
    "    if isinstance(sym, Nonterminal):\n",
    "        return Span(sym, start, end)\n",
    "    else:\n",
    "        return sym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a forest is indeed really simple, we just need to return a new CFG with rules derived from complete items in the passive set. The rules will have their nonterminals annotated into spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forest(complete_items: list, forest_start: Nonterminal):\n",
    "    \"\"\"\n",
    "    Converts complete items from CKY+ into a forest, that is, a CFG whose rules have spans for nonterminals.\n",
    "\n",
    "    :param complete_items: a collection of dotted items which are complete (dot at the end of the RHS)\n",
    "    :param forest_start: the start nonterminal (a Span) of the forest\n",
    "    \"\"\"\n",
    "    if not isinstance(forest_start, Span):\n",
    "        raise ValueError('The start symbol of a forest should be a span')\n",
    "    forest = CFG(forest_start)\n",
    "    for item in complete_items:\n",
    "        lhs = make_span(item.lhs, item.start, item.dot)\n",
    "        rhs = []\n",
    "        for i, sym in enumerate(item.rule.rhs):\n",
    "            if isinstance(sym, Terminal):\n",
    "                rhs.append(sym)\n",
    "            else:\n",
    "                rhs.append(make_span(sym, item.state(i), item.state(i + 1)))\n",
    "        forest.add(Rule(lhs, rhs))\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"deduction\"> Deduction\n",
    "\n",
    "Start with axioms and exhaustively apply inference rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cky(cfg: CFG, sentence):\n",
    "    A = Agenda()\n",
    "    for item in axioms(cfg, sentence):\n",
    "        A.push(item)\n",
    "    while A:\n",
    "        item = A.pop()\n",
    "        # a complete item can be used to complete other items\n",
    "        # alternatively, we may be able to advance an incomplete item\n",
    "        #  whose next symbol is a nonterminal by combining it with some passive complete item\n",
    "        if item.is_complete() or isinstance(item.next, Nonterminal):\n",
    "            for new in complete(item, A):\n",
    "                A.push(new)\n",
    "        else:  # here we have a terminal ahead of the dot, thus only scan is possible\n",
    "            new = scan(item, sentence)\n",
    "            if new is not None:  # if we managed to scan\n",
    "                A.push(new)\n",
    "        A.make_passive(item)\n",
    "    forest_start = make_span(cfg.start, 0, len(sentence))\n",
    "    forest = make_forest(A.itercomplete(), forest_start)\n",
    "    if forest.can_rewrite(forest_start):\n",
    "        return forest\n",
    "    else:\n",
    "        return CFG(forest_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = cky(G, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S:0-8]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.can_rewrite(forest.start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S:0-8] -> [NP:0-2] [VP:2-8]\n",
      "[NP:0-2] -> [DT:0-1] [NN:1-2]\n",
      "[NP:1-2] -> [NN:1-2]\n",
      "[NP:3-5] -> [DT:3-4] [NN:4-5]\n",
      "[NP:3-8] -> [NP:3-5] [PP:5-8]\n",
      "[NP:4-5] -> [NN:4-5]\n",
      "[NP:4-8] -> [NP:4-5] [PP:5-8]\n",
      "[NP:6-8] -> [DT:6-7] [NN:7-8]\n",
      "[NP:7-8] -> [NN:7-8]\n",
      "[PP:5-8] -> [IN:5-6] [NP:6-8]\n",
      "[S:0-5] -> [NP:0-2] [VP:2-5]\n",
      "[S:1-5] -> [NP:1-2] [VP:2-5]\n",
      "[S:1-8] -> [NP:1-2] [VP:2-8]\n",
      "[VP:2-5] -> [Vt:2-3] [NP:3-5]\n",
      "[VP:2-8] -> [VP:2-5] [PP:5-8]\n",
      "[VP:2-8] -> [Vt:2-3] [NP:3-8]\n",
      "[DT:0-1] -> 'the'\n",
      "[DT:3-4] -> 'the'\n",
      "[DT:6-7] -> 'a'\n",
      "[IN:5-6] -> 'with'\n",
      "[NN:1-2] -> 'man'\n",
      "[NN:4-5] -> 'dog'\n",
      "[NN:7-8] -> 'telescope'\n",
      "[Vt:2-3] -> 'saw'\n"
     ]
    }
   ],
   "source": [
    "print(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if we modify the sentence in a way that it can't be parsed by G we will get an empty forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_forest = cky(G, sentence + [Terminal('!')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S:0-9]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_forest.start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_forest.can_rewrite(empty_forest.start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a name=\"pcfg\"> PCFG recap\n",
    "\n",
    "A probabilistic CFG is a simple extension to CFGs where we assign a joint probability distribution over the space of context-free *derivations*. \n",
    "\n",
    "A random **derivation** $D = \\langle R_1, \\ldots, R_m \\rangle$ is a sequence of $m$ *random rule applications*.\n",
    "A random rule is a pair of a random LHS nonterminal $V$ and a random RHS sequence $\\beta$, where $V \\rightarrow \\beta$ corresponds to a valid rule in the grammar.\n",
    "\n",
    "We assume that a derivation is generated one rule at a time and each rule is generated independently. Moreover, the probability value of a rule is given by a conditional probability distribution over RHS sequences given LHS nonterminal. \n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "P_{D|M}(r_1^m|m) &= \\prod_{i=1}^m P_R(r_i) \\\\\n",
    " &= \\prod_{i=1}^m P_{\\text{RHS}|\\text{LHS}}(\\beta_i | v_i)\\\\\n",
    " &= \\prod_{i=1}^m \\text{Cat}(\\beta_i | \\boldsymbol \\theta^{v_i})\\\\\n",
    " &= \\prod_{i=1}^m \\theta_{v_i \\rightarrow \\beta_i}\\\\\n",
    "\\end{align}\n",
    "\n",
    "We can implement PCFGs rather easily by pairing a CFG grammar with a dictionary mapping from rules to their probabilities. But we must remember that for each given LHS symbol, the probability values of all of its rewriting rules must sum to 1.\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{\\beta} \\theta_{v \\rightarrow \\beta} = 1\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <a name=\"inside\"> Inside algorithm\n",
    "\n",
    "\n",
    "This is the core of this lab, the inside recursion. The inside recursion (also known as **value recursion**) is incredibly general, it can be used to compute a range of interesting quantities.\n",
    "\n",
    "The formula below corresponds to the recursion:\n",
    "\n",
    "\\begin{align}\n",
    "(1)\\qquad    I(v) &= \n",
    "    \\begin{cases}\n",
    "        \\bar{1} & \\text{if }v \\text{ is terminal and } \\text{BS}(v) = \\emptyset\\\\\n",
    "        \\bar{0} & \\text{if }v \\text{ is nonterminal and } \\text{BS}(v) = \\emptyset \\\\\n",
    "        \\displaystyle\\bigoplus_{\\frac{a_1 \\ldots a_n}{v: \\theta} \\in \\text{BS}(v)} \\theta \\otimes \\bigotimes_{i=1}^n I(a_i) & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "In this formula $\\text{BS}(v)$ is the *backward-star* of the node, or the set of edges **incoming** to the node. That is, all edges (rules with spans) that have that node as an LHS symbol. There is one detail important to remember. In principle only *terminal* nodes would have an empty backward-star. But because our parsing strategy can produce some dead-end nodes (nodes that cannot be expanded) we will have some nonterminal nodes with empty backward-star. Those are special cases, which we treat specially. Essentially, we give them an inside value of $\\bar 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"semirings\">  Semirings\n",
    "\n",
    "In this formula we use generalised sum $\\oplus$ and generalised product $\\otimes$ which we explain below.\n",
    "\n",
    "A **semiring** is algebraic structure $\\langle \\mathbb K, \\oplus, \\otimes, \\bar 0, \\bar 1\\rangle$ which corresponds to a set $\\mathbb K$ equipped with addition $\\oplus$ and multiplication $\\otimes$.\n",
    "\n",
    "### Real semiring\n",
    "\n",
    "For example, the algebra you learnt at school is a semiring! \n",
    "The set of interest is the real line $\\mathbb K = \\mathbb R$.\n",
    "\n",
    "Then if we have two real numbers, $a \\in \\mathbb R$ and $b \\in \\mathbb R$, we define **sum** as\n",
    "\\begin{equation}\n",
    "a \\oplus b = a + b\n",
    "\\end{equation}\n",
    "which is simply the standard addition.\n",
    "The additive identity is the value in the set that does not affect summation, we indicate it by $\\bar 0$. In this case, we are talking about the real number 0:\n",
    "\\begin{equation}\n",
    "a \\oplus \\bar 0 = a + 0 = a\n",
    "\\end{equation}\n",
    "\n",
    "We can also define **multiplication**\n",
    "\\begin{equation}\n",
    "a \\otimes b = a \\times b\n",
    "\\end{equation}\n",
    "which is simply the standard multiplication.\n",
    "The multiplicative identity is the value in the set that does not affect multiplication, we indicate it by $\\bar 1$. In this case, we are talking about the read number 1:\n",
    "\\begin{equation}\n",
    "a \\otimes \\bar 1 = a \\times 1 = a\n",
    "\\end{equation}\n",
    "\n",
    "### Log-Probability semiring\n",
    "\n",
    "When we compute a log-marginal, we are essentially using a logarithmic semiring. \n",
    "\n",
    "Then the set of interest is the set of log-probability values. Probabilities range between $0$ and $1$ and therefore log-probabilities range from $-\\infty$ (which is $\\log 0$) to $0$ (which is $\\log 1$). We denote this set $\\mathbb K = \\mathbb R_{\\le 0} \\cup \\{-\\infty\\}$.\n",
    "\n",
    "Then if we have two log-probability values $a \\in \\mathbb K$ and $b \\in \\mathbb K$, our sum becomes\n",
    "\\begin{equation}\n",
    "a \\oplus b = \\log(\\exp a + \\exp b)\n",
    "\\end{equation}\n",
    "Here we first exponentiate the values bringing them back to the real semiring (where we know how to sum), then we use the standard sum (from high school), and convert the result back to the log-probability semiring by applying $\\log$ to the result.\n",
    "\n",
    "Our product becomes\n",
    "\\begin{equation}\n",
    "a \\otimes b = a + b\n",
    "\\end{equation}\n",
    "which exploits a basic property of logarithms.\n",
    "\n",
    "\n",
    "Our additive identity is\n",
    "\\begin{equation}\n",
    "a \\oplus \\bar 0 = \\log (\\exp a + \\underbrace{\\exp(-\\infty)}_{0}) = \\log \\exp a = a\n",
    "\\end{equation}\n",
    "this is the case because exponentiating an infinitely negative number converges to $0$.\n",
    "\n",
    "Finally, our multiplicative identity is\n",
    "\\begin{equation}\n",
    "a \\otimes \\bar 1 = a \\times 1 = a\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "The interesting thing about semirings is that they manipulate different *types of numbers* but they are coherent with the basic axioms of math that we are used to. They help us realise that several algorithms are actually all the same, but they happen to operate under different algebraic structures (read: different definitions of what sum and multiplication are)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a general class for semirings and you will implement various specialisations. \n",
    "This class will only contain **class methods** this makes the class more or less like a package that can be used to organise coherent functions without really storing any content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semiring:\n",
    "    \"\"\"\n",
    "    This is the interface for semirings.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_real(cls, a: float):\n",
    "        \"\"\"This method takes a number in the Real semiring and converts it to the semiring of interest\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'You need to implement this in the child class')\n",
    "\n",
    "    @classmethod\n",
    "    def to_real(cls, a: float):\n",
    "        \"\"\"This method takes a number in this semiring and converts it to the Real semiring\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'You need to implement this in the child class')\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        \"\"\"This method returns the multiplicative identity of the semiring\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'You need to implement this in the child class')\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        \"\"\"This method returns the additive identity of the semiring\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'You need to implement this in the child class')\n",
    "\n",
    "    @classmethod\n",
    "    def plus(cls, a, b):\n",
    "        \"\"\"\n",
    "        This method sums a and b (in the semiring sense)\n",
    "            where a and b are elements already converted to the type of numbers manipulated by the semiring\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'You need to implement this in the child class')\n",
    "\n",
    "    @classmethod\n",
    "    def times(cls, a, b):\n",
    "        \"\"\"\n",
    "        This method multiplies a and b (in the semiring sense)\n",
    "            where a and b are elements already converted to the type of numbers manipulated by the semiring\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            'You need to implement this in the child class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement for you the *Marginal semiring*, that is, the basic algebra from school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarginalSemiring(Semiring):\n",
    "\n",
    "    @classmethod\n",
    "    def from_real(cls, a: float):\n",
    "        return a\n",
    "\n",
    "    @classmethod\n",
    "    def to_real(cls, a: float):\n",
    "        return a\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        return 1.\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        return 0.\n",
    "\n",
    "    @classmethod\n",
    "    def plus(cls, a, b):\n",
    "        return a + b\n",
    "\n",
    "    @classmethod\n",
    "    def times(cls, a, b):\n",
    "        return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarginalSemiring.from_real(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarginalSemiring.to_real(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarginalSemiring.plus(0.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarginalSemiring.times(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarginalSemiring.one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarginalSemiring.zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we also implement for you the *ViterbiSemiring* used to compute maximum probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ViterbiSemiring(Semiring):\n",
    "\n",
    "    @classmethod\n",
    "    def from_real(cls, a: float):\n",
    "        return a\n",
    "\n",
    "    @classmethod\n",
    "    def to_real(cls, a: float):\n",
    "        return a\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        return 1.\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        return 0.\n",
    "\n",
    "    @classmethod\n",
    "    def plus(cls, a, b):\n",
    "        return np.maximum(a, b)\n",
    "\n",
    "    @classmethod\n",
    "    def times(cls, a, b):\n",
    "        return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ViterbiSemiring.times(0.2, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note how the following will pick the maximum rather than accumulate the numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ViterbiSemiring.plus(0.1, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you implement the $\\log$ variants of both semirings:\n",
    "\n",
    "\n",
    "<a name=\"ex7-6\" style=\"color:red\">**Exercise 7-6**</a> **[6 points]** Implement LogMarginalSemiring below as a log-variant of the MarginalSemiring as well as LogViterbiSemiring as a log-variant of the ViterbiSemiring. Run examples of all methods and confirm that the quantities they compute correspond to the correct quantities when converted back to the Real semiring using `to_real`.\n",
    "\n",
    "* **[3 points]** LogMarginalSemiring\n",
    "* **[3 points]** LogViterbiSemiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMarginalSemiring(Semiring):\n",
    "\n",
    "    @classmethod\n",
    "    def from_real(cls, a: float):\n",
    "        return np.log(a)\n",
    "\n",
    "    @classmethod\n",
    "    def to_real(cls, a: float):\n",
    "        return np.exp(a)\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        return 0.\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        return -float(\"inf\")\n",
    "\n",
    "    @classmethod\n",
    "    def plus(cls, a, b):\n",
    "        return np.log(np.exp(a) + np.exp(b))\n",
    "\n",
    "    @classmethod\n",
    "    def times(cls, a, b):\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6094379124341003 -1.2039728043259361\n",
      "-2.8134107167600364 -0.6931471805599453\n",
      "0.06 0.5\n"
     ]
    }
   ],
   "source": [
    "a = LogMarginalSemiring.from_real(0.2)\n",
    "b = LogMarginalSemiring.from_real(0.3)\n",
    "print(a, b)\n",
    "\n",
    "x = LogMarginalSemiring.times(a, b)\n",
    "y = LogMarginalSemiring.plus(a, b)\n",
    "print(x, y)\n",
    "\n",
    "x = LogMarginalSemiring.to_real(x)\n",
    "y = LogMarginalSemiring.to_real(y)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogViterbiSemiring(Semiring):\n",
    "\n",
    "    @classmethod\n",
    "    def from_real(cls, a: float):\n",
    "        return np.log(a)\n",
    "\n",
    "    @classmethod\n",
    "    def to_real(cls, a: float):\n",
    "        return np.exp(a)\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        return 0.\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        return -float(\"inf\")\n",
    "\n",
    "    @classmethod\n",
    "    def plus(cls, a, b):\n",
    "        return max(a, b)\n",
    "\n",
    "    @classmethod\n",
    "    def times(cls, a, b):\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6094379124341003 -1.2039728043259361\n",
      "-2.8134107167600364 -1.2039728043259361\n",
      "0.06 0.3\n"
     ]
    }
   ],
   "source": [
    "a = LogViterbiSemiring.from_real(0.2)\n",
    "b = LogViterbiSemiring.from_real(0.3)\n",
    "print(a, b)\n",
    "\n",
    "x = LogViterbiSemiring.times(a, b)\n",
    "y = LogViterbiSemiring.plus(a, b)\n",
    "print(x, y)\n",
    "\n",
    "x = LogViterbiSemiring.to_real(x)\n",
    "y = LogViterbiSemiring.to_real(y)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the inside recursion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the inside recursion you need the weight (parameter converted to the appropriate semiring) of the rule that justifies each edge. \n",
    "\n",
    "For that we provide you with a helper function. It receives an edge (Rule with spans) and the cpds of the original grammar and returns the correct parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def get_parameter(edge: Rule, cpds: Dict[Nonterminal, Dict[Rule, float]]):\n",
    "    base_rhs = [node.base_nonterminal if isinstance(\n",
    "        node, Span) else node for node in edge.rhs]\n",
    "    base_rule = Rule(edge.lhs.base_nonterminal, base_rhs)\n",
    "    return cpds[base_rule.lhs][base_rule]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [NP:7-8] -> [NN:7-8]\n",
      "1.0 [S:0-5] -> [NP:0-2] [VP:2-5]\n",
      "0.4 [DT:6-7] -> 'a'\n",
      "0.4 [NP:6-8] -> [DT:6-7] [NN:7-8]\n",
      "0.1 [NP:4-5] -> [NN:4-5]\n",
      "1.0 [S:1-5] -> [NP:1-2] [VP:2-5]\n",
      "0.4 [NN:1-2] -> 'man'\n",
      "0.3 [NP:3-8] -> [NP:3-5] [PP:5-8]\n",
      "0.3 [VP:2-5] -> [Vt:2-3] [NP:3-5]\n",
      "1.0 [S:1-8] -> [NP:1-2] [VP:2-8]\n",
      "0.1 [NN:7-8] -> 'telescope'\n",
      "0.4 [VP:2-8] -> [VP:2-5] [PP:5-8]\n",
      "0.1 [NP:1-2] -> [NN:1-2]\n",
      "0.4 [Vt:2-3] -> 'saw'\n",
      "0.5 [IN:5-6] -> 'with'\n",
      "0.4 [NP:0-2] -> [DT:0-1] [NN:1-2]\n",
      "0.4 [NP:3-5] -> [DT:3-4] [NN:4-5]\n",
      "0.6 [DT:0-1] -> 'the'\n",
      "1.0 [PP:5-8] -> [IN:5-6] [NP:6-8]\n",
      "0.3 [NP:4-8] -> [NP:4-5] [PP:5-8]\n",
      "1.0 [S:0-8] -> [NP:0-2] [VP:2-8]\n",
      "0.3 [NN:4-5] -> 'dog'\n",
      "0.3 [VP:2-8] -> [Vt:2-3] [NP:3-8]\n",
      "0.6 [DT:3-4] -> 'the'\n"
     ]
    }
   ],
   "source": [
    "# Now if you ever need to get the parameter for a rule in the grammar you can use the function above\n",
    "# For example,\n",
    "for edge in forest:\n",
    "    print(get_parameter(edge, cpds), edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-7\" style=\"color:red\">**Exercise 7-7**</a> **[15 points]** Now you should implement the inside recursion below\n",
    "\n",
    "* see below for example of inside values for a correct implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.644864e-06 4.6e-06\n",
      "2.6542079999999997e-06 2.6e-06\n"
     ]
    }
   ],
   "source": [
    "def compute_inside_table(forest: CFG, cpds: Dict[Nonterminal, Dict[Rule, float]], semiring: Semiring):\n",
    "    \"\"\"\n",
    "    Computes the inside table, that is, the table that assigns an inside value to each \n",
    "        node in the forest, where a node is a Span.\n",
    "\n",
    "        For convenience, this table may also contain inside values for nodes that are not spans, such as the leaves\n",
    "            or terminals of the forest, but then that inside should be semiring.one()\n",
    "\n",
    "        Our parsing strategies sometimes create useless nodes, these are nonterminal nodes that have no way\n",
    "            of being expanded (there are no edges incoming to those nodes, they have an empty backward-star).\n",
    "            We consider those nodes have an inside value of semiring.zero().\n",
    "            This is necessary to circumvent the fact that the parsing strategy can create such useless items.\n",
    "\n",
    "    :param forest: a forest as produced by CKY+\n",
    "    :param cpds: the cpds of the original grammar\n",
    "    :param semiring: a choice of Semiring\n",
    "    :return: inside table as a dictionary from a Span to an inside value (as a number in the semiring)\n",
    "    \"\"\"\n",
    "    inside_table = {}\n",
    "    for edge in forest:\n",
    "\n",
    "        # This function does the one top-level iteration and fills dict,\n",
    "        # real recursion happens somewhere else. See that thing for a\n",
    "        # cleaner version of the algorithm itself.\n",
    "        weight = semiring.from_real(get_parameter(edge, cpds))\n",
    "        lhs = edge._lhs\n",
    "        if lhs not in inside_table:\n",
    "            inside_table[lhs] = semiring.zero()\n",
    "        prod = semiring.one()\n",
    "        for right_element in edge._rhs:\n",
    "            prod = semiring.times(prod,\n",
    "                                  down_the_hole(forest, cpds, right_element, semiring))\n",
    "\n",
    "            if not forest.can_rewrite(right_element):\n",
    "                # This is a terminal or one of those 0 things.\n",
    "                inside_table[right_element] = prod\n",
    "\n",
    "        inside_table[lhs] = semiring.plus(inside_table[lhs],\n",
    "                                          semiring.times(weight, prod))\n",
    "    return inside_table\n",
    "\n",
    "\n",
    "def down_the_hole(forest, cpds, right_element, semiring):\n",
    "\n",
    "    # Take sum of weight * inner product for every possible inference.\n",
    "    if forest.can_rewrite(right_element):\n",
    "        s = semiring.zero()\n",
    "        for edge in forest[right_element]:\n",
    "            weight = semiring.from_real(get_parameter(edge, cpds))\n",
    "            prod = semiring.one()\n",
    "            for r in edge._rhs:\n",
    "\n",
    "                # That inner product requires recursion to get to definite 1 or 0.\n",
    "                prod = semiring.times(prod,\n",
    "                                      down_the_hole(forest, cpds, r, semiring))\n",
    "            s = semiring.plus(s, semiring.times(weight, prod))\n",
    "        return s\n",
    "\n",
    "    # These are the base cases.\n",
    "    if isinstance(right_element, Terminal):\n",
    "        return semiring.one()\n",
    "    return semiring.zero()\n",
    "\n",
    "\n",
    "inside_table = compute_inside_table(forest, cpds, LogMarginalSemiring)\n",
    "print(LogMarginalSemiring.to_real(inside_table[forest.start]), 4.6e-06)\n",
    "\n",
    "viterbi_table = compute_inside_table(forest, cpds, LogViterbiSemiring)\n",
    "print(LogViterbiSemiring.to_real(viterbi_table[forest.start]), 2.6e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even define a semiring to count! Imagine that a semiring maps from the real numbers by saying that if something has non-zero probability it counts as $1$ and if it has zero probability it counts as $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountSemiring(Semiring):\n",
    "\n",
    "    @classmethod\n",
    "    def from_real(cls, a: float):\n",
    "        \"\"\"Map to 1 if a bigger than 0\"\"\"\n",
    "        return 1. if a > 0. else 0.\n",
    "\n",
    "    @classmethod\n",
    "    def to_real(cls, a: float):\n",
    "        return a\n",
    "\n",
    "    @classmethod\n",
    "    def one(cls):\n",
    "        return 1.\n",
    "\n",
    "    @classmethod\n",
    "    def zero(cls):\n",
    "        return 0.\n",
    "\n",
    "    @classmethod\n",
    "    def plus(cls, a, b):\n",
    "        return a + b\n",
    "\n",
    "    @classmethod\n",
    "    def times(cls, a, b):\n",
    "        return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the inside algorithm to find the number of **derivations** in the parse forest! \n",
    "\n",
    "If your inside implementation is corret, this is what your result should look like:\n",
    "\n",
    "```python\n",
    "count_table = compute_inside_table(forest, cpds, CountSemiring)\n",
    "CountSemiring.to_real(count_table[forest.start])\n",
    "2.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0 2.0\n"
     ]
    }
   ],
   "source": [
    "count_table = compute_inside_table(forest, cpds, CountSemiring)\n",
    "print(CountSemiring.to_real(count_table[forest.start]), 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't this great? :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to compute the actual Viterbi derivation!\n",
    "\n",
    "## Viterbi derivation\n",
    "\n",
    "The Viterbi path is a top-down traversal of the forest, where each time we have to choose which rule/edge to use to expand a certain nonterminal symbol (span node), we choose the one whose inside value is maximum. But recall that the inside value associated with an *edge* must take into account the weight of the edge and the inside value of its children. Of course, all of this must happen within a maximising semiring (e.g. LogViterbiSemiring or ViterbiSemiring). \n",
    "\n",
    "\n",
    "\\begin{align} \n",
    "(2) \\qquad e^\\star &= \\arg\\!\\max_{e \\in \\text{BS(v)}} \\theta \\otimes \\bigotimes_{i=1}^n I(a_i) \\\\\n",
    "    &~\\text{where }e:=\\frac{a_1, \\ldots, a_n}{v}:\\theta\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-8\" style=\"color:red\">**Exercise 7-8**</a> **[5 points]** Implement a function that returns the Viterbi derivation (a sequence of rule applications that attains maximum probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([S:0-8] -> [NP:0-2] [VP:2-8],\n",
       "  [NP:0-2] -> [DT:0-1] [NN:1-2],\n",
       "  [DT:0-1] -> 'the',\n",
       "  [NN:1-2] -> 'man',\n",
       "  [VP:2-8] -> [VP:2-5] [PP:5-8],\n",
       "  [VP:2-5] -> [Vt:2-3] [NP:3-5],\n",
       "  [Vt:2-3] -> 'saw',\n",
       "  [NP:3-5] -> [DT:3-4] [NN:4-5],\n",
       "  [DT:3-4] -> 'the',\n",
       "  [NN:4-5] -> 'dog',\n",
       "  [PP:5-8] -> [IN:5-6] [NP:6-8],\n",
       "  [IN:5-6] -> 'with',\n",
       "  [NP:6-8] -> [DT:6-7] [NN:7-8],\n",
       "  [DT:6-7] -> 'a',\n",
       "  [NN:7-8] -> 'telescope'),\n",
       " 'the man saw the dog with a telescope')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def viterbi_derivation(forest: CFG, cpds: Dict[Nonterminal, Dict[Rule, float]], inside_table: Dict[Symbol, float], semiring: Semiring):\n",
    "    \"\"\"\n",
    "    Return the derivation (and its yield) that attains maximum probability.\n",
    "\n",
    "    This is a top-down traversal from the root, where for each node v that we need to expand, we \n",
    "        solve equation (2) above.\n",
    "\n",
    "    :param forest: a forest\n",
    "    :param cpds: cpds of the original grammar\n",
    "    :param inside_table: inside values produced with a certain maximising semiring\n",
    "    :param semiring: a maximising semiring e.g. ViterbiSemiring or LogViterbiSemiring\n",
    "    :returns: a tuple\n",
    "        - first element is an ordered list of rule applications\n",
    "        - second element is the yield of the derivation \n",
    "    \"\"\"\n",
    "    words = []\n",
    "    done = []\n",
    "    todo = [forest.start]  # using as FIFO stack\n",
    "    while todo:\n",
    "        x = todo[0]\n",
    "        del todo[0]\n",
    "        if not forest.can_rewrite(x):\n",
    "            words.append(str(x))\n",
    "        else:\n",
    "            best_p = semiring.zero()\n",
    "            for edge in forest[x]:\n",
    "                p = semiring.from_real(get_parameter(edge, cpds))\n",
    "                if p > best_p:\n",
    "                    best_p = p\n",
    "                    best_edge = edge\n",
    "            todo = list(best_edge.rhs) + todo\n",
    "            done.append(best_edge)\n",
    "    return (tuple(done), ' '.join(words).replace(\"'\", \"\"))\n",
    "\n",
    "\n",
    "viterbi_derivation(forest, cpds, viterbi_table, LogViterbiSemiring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your implementation is correct you should get\n",
    "\n",
    "```python\n",
    "viterbi_derivation(forest, cpds, viterbi_table, LogViterbiSemiring)\n",
    "(([S:0-8] -> [NP:0-2] [VP:2-8],\n",
    "  [NP:0-2] -> [DT:0-1] [NN:1-2],\n",
    "  [DT:0-1] -> 'the',\n",
    "  [NN:1-2] -> 'man',\n",
    "  [VP:2-8] -> [VP:2-5] [PP:5-8],\n",
    "  [VP:2-5] -> [Vt:2-3] [NP:3-5],\n",
    "  [Vt:2-3] -> 'saw',\n",
    "  [NP:3-5] -> [DT:3-4] [NN:4-5],\n",
    "  [DT:3-4] -> 'the',\n",
    "  [NN:4-5] -> 'dog',\n",
    "  [PP:5-8] -> [IN:5-6] [NP:6-8],\n",
    "  [IN:5-6] -> 'with',\n",
    "  [NP:6-8] -> [DT:6-7] [NN:7-8],\n",
    "  [DT:6-7] -> 'a',\n",
    "  [NN:7-8] -> 'telescope'),\n",
    " ('the', 'man', 'saw', 'the', 'dog', 'with', 'a', 'telescope'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can draw trees using NLTK, here is an example, you can adjust this to visualise trees predicted by your own Viterbi derivation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('all')\n",
    "# from nltk.tree import Tree\n",
    "# parse_sent = '(S (NP (DT the) (NN cat)) (VP (VBD ate) (NP (DT a) (NN cookie))))'\n",
    "# t = Tree.fromstring(parse_sent)\n",
    "# t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earley parsing\n",
    "\n",
    "\n",
    "Earley parser is a more conservative, top-down parser, it typically enumerates far less items than CKY+. \n",
    "Answer the questions below (not optional) and as an optional extra contribute an implementation of Earley parser (you may reuse data structures developed for CKY+).\n",
    "\n",
    "Mostly it requires a change of *axioms* and one additional inference rule (i.e. PREDICT). Tip: be careful not to predict the same item multiple times ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{Item} &\\qquad [i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, \\beta_\\square, j] \\\\\n",
    "\\text{Goal} &\\qquad [1, S \\rightarrow \\beta_\\blacksquare \\, \\bullet, n]  \\\\\n",
    "\\text{Axioms} &\\qquad [0, S \\rightarrow \\bullet \\alpha_\\square, 0] &~\\text{ for all } S \\rightarrow \\alpha \\in \\mathcal R \\\\\n",
    "\\text{Scan} &\\qquad \\frac{[i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, x_{j+1}  \\, \\beta_\\square, j]}{[i, X \\rightarrow \\alpha_\\blacksquare \\, x_{j+1} \\bullet \\, \\beta_\\square, j + 1]} \\\\\n",
    "\\text{Predict} &\\qquad \\frac{[i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, Y_{j+1}  \\, \\beta_\\square, j]}{[j, Y \\rightarrow \\gamma_\\square, j]} &~\\text{for all } Y \\rightarrow \\gamma \\in \\mathcal R\\\\\n",
    "\\text{Complete} &\\qquad \\frac{[i, X \\rightarrow \\alpha_\\blacksquare \\, \\bullet \\, Y \\, \\beta_\\square ,k] [k, Y \\rightarrow \\gamma_\\blacksquare \\, \\bullet , j]}{[i,  X \\rightarrow \\alpha_\\blacksquare \\, Y_{k,j} \\, \\bullet \\, \\beta_\\square , j]}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-9\" style=\"color:red\">**Exercise 7-9**</a> ***THIS IS EXERCISE IS OPTIONAL, ITS POINTS COUNT AS BONUS*** \n",
    "\n",
    "* **[0.25 points]** Axioms\n",
    "\n",
    "The axiom is the/a starting rule(s), with the to be parsed sentence after the dot. Formulated simpler: try to parse the sentence, top-down for each of the starting rules. The start and end count are 0 because we're working top-down.\n",
    "\n",
    "* **[0.25 points]** Scan\n",
    "\n",
    "If there is a terminal which can be parsed at the end of the currently parsed sentence (upper part of rule), then parse it and update the sentence (bottom part of rule).\n",
    "\n",
    "* **[0.25 points]** Predict\n",
    "\n",
    "The predict rule looks (top-down ofc) for all terminals (or, productions) that can be obtained from the currently parsed sentence.\n",
    "\n",
    "* **[0.25 points]** Complete\n",
    "\n",
    "If there is an item at the end of the currently parsed sentence (top left), which is already parsed (passed over by dot) (top right), update parse of this part of the sentence (bottom)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ex7-10\" style=\"color:red\">**Exercise 7-10**</a> ***THIS IS EXERCISE IS OPTIONAL, ITS POINTS COUNT AS BONUS*** \n",
    "\n",
    "\n",
    "Implement Earley parser and show that it works by parsing the running example and showing the inside value of the GOAL item for LogMarginalSemiring, LogViterbiSemiring, and CountSemiring.\n",
    "\n",
    "\n",
    "* Points: this exercise is worth 1 extra absolut point added directly to your final grade for *practicals*. Recall that *practicals* account at most for 40% of your grade, thus we first compute your grade without bonuses, then we add the points you earn here. The resulting grade however can never exceed 4 points (that is, 40% of the maximum possible final grade).\n",
    "* Note: we will grade this exercise using the scale: 0, 1/4, 1/2, 3/4, 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[S] -> [NP] [VP], (7,)]\n",
      "[[S] -> [NP] [VP], (6,)]\n",
      "[[S] -> [NP] [VP], (5,)]\n",
      "[[S] -> [NP] [VP], (4,)]\n",
      "[[S] -> [NP] [VP], (3,)]\n",
      "[[S] -> [NP] [VP], (2,)]\n",
      "[[S] -> [NP] [VP], (1,)]\n",
      "[[S] -> [NP] [VP], (0,)]\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "[S:0-8]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-26c22c6d7816>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-------------------------------------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[0minside_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_inside_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcpds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogMarginalSemiring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogMarginalSemiring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minside_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4.6e-06\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[0mviterbi_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_inside_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcpds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogViterbiSemiring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogViterbiSemiring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviterbi_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.6e-06\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: [S:0-8]"
     ]
    }
   ],
   "source": [
    "# INCOMPLETE!!!\n",
    "\n",
    "def earley_axioms(cfg: CFG, sentence: list):\n",
    "    # Returns just derivations for S\n",
    "    items = []\n",
    "    for rule in cfg:\n",
    "        if str(rule._lhs) == \"[S]\":\n",
    "            for i, x in enumerate(sentence):\n",
    "                items.append(Item(rule, [i]))\n",
    "    return items\n",
    "\n",
    "\n",
    "def earley_scan(cfg, item: Item, sentence):\n",
    "    res = []\n",
    "    for x in item._rule._rhs:\n",
    "        res.append(x)\n",
    "\n",
    "\n",
    "def earley_predict(cfg, item, A, sentence):\n",
    "    \"\"\" Goes top-down until terminal, that terminal\n",
    "        is the thing that's predicted. Should update\n",
    "        A. \"\"\"\n",
    "    print(item[0])\n",
    "    for x in item[0]._rhs:\n",
    "        for rule in cfg:\n",
    "            print(rule, x)\n",
    "            if str(rule._lhs) == str(x):\n",
    "                print(rule)\n",
    "\n",
    "\n",
    "def earley(cfg: CFG, sentence):\n",
    "    \"\"\" This thing is probably okay,\n",
    "        the functions above suck. \"\"\"\n",
    "    A = Agenda()\n",
    "    for item in earley_axioms(cfg, sentence):\n",
    "        A.push(item)\n",
    "\n",
    "    # Now A contains the S derivation for every word in sentence.\n",
    "    i = 0  # temp, to stop loops\n",
    "    while A:\n",
    "        item = A.pop()\n",
    "        print(item)\n",
    "        i += 1\n",
    "        if i > 30:\n",
    "            break\n",
    "        if not item.is_complete():\n",
    "            if not isinstance(item.next, Nonterminal):\n",
    "                earley_predict(cfg, item, A, sentence)\n",
    "            else:\n",
    "                new = earley_scan(cfg, item, sentence)\n",
    "                if new is not None:\n",
    "                    for x in new:\n",
    "                        A.push(x)\n",
    "        else:\n",
    "            for new in complete(item, A):\n",
    "                A.push(new)\n",
    "        A.make_passive(item)\n",
    "    forest_start = make_span(cfg.start, 0, len(sentence))\n",
    "    forest = make_forest(A.itercomplete(), forest_start)\n",
    "    if forest.can_rewrite(forest_start):\n",
    "        return forest\n",
    "    else:\n",
    "        return CFG(forest_start)\n",
    "\n",
    "\n",
    "forest = earley(G, sentence)\n",
    "print(\"-------------------------------------------------------------\")\n",
    "inside_table = compute_inside_table(forest, cpds, LogMarginalSemiring)\n",
    "print(LogMarginalSemiring.to_real(inside_table[forest.start]), 4.6e-06)\n",
    "viterbi_table = compute_inside_table(forest, cpds, LogViterbiSemiring)\n",
    "print(LogViterbiSemiring.to_real(viterbi_table[forest.start]), 2.6e-06)\n",
    "count_table = compute_inside_table(forest, cpds, CountSemiring)\n",
    "print(CountSemiring.to_real(count_table[forest.start]), 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
